<!DOCTYPE html>
<html lang="it" xml:lang="it">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Appunti - Machine Learning</title>
  <meta name="description" content="Appunti - Machine Learning" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Appunti - Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Appunti - Machine Learning" />
  
  
  

<meta name="author" content="Alberto Filosa" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a > Data Management </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#data"><i class="fa fa-check"></i><b>1</b> Data</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#exploration"><i class="fa fa-check"></i><b>1.1</b> Exploration</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#missing-replacement"><i class="fa fa-check"></i><b>1.2</b> Missing Replacement</a></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#pre-processing"><i class="fa fa-check"></i><b>1.3</b> Pre-Processing</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path=""><a href="#classification"><i class="fa fa-check"></i><b>2</b> Classification</a><ul>
<li class="chapter" data-level="2.1" data-path=""><a href="#tecniche-di-classificazione"><i class="fa fa-check"></i><b>2.1</b> Tecniche di Classificazione</a><ul>
<li class="chapter" data-level="2.1.1" data-path=""><a href="#modelli-euristici"><i class="fa fa-check"></i><b>2.1.1</b> Modelli Euristici</a></li>
<li class="chapter" data-level="2.1.2" data-path=""><a href="#modelli-di-separation"><i class="fa fa-check"></i><b>2.1.2</b> Modelli di Separation</a></li>
<li class="chapter" data-level="2.1.3" data-path=""><a href="#modelli-probabilistici"><i class="fa fa-check"></i><b>2.1.3</b> Modelli Probabilistici</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path=""><a href="#performance-evaluation"><i class="fa fa-check"></i><b>3</b> Performance Evaluation</a><ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#misure-di-performance"><i class="fa fa-check"></i><b>3.1</b> Misure di performance</a></li>
<li class="chapter" data-level="3.2" data-path=""><a href="#comparing-classifiers"><i class="fa fa-check"></i><b>3.2</b> Comparing Classifiers</a><ul>
<li class="chapter" data-level="3.2.1" data-path=""><a href="#intervallo-di-confidenza"><i class="fa fa-check"></i><b>3.2.1</b> Intervallo di Confidenza</a></li>
<li class="chapter" data-level="3.2.2" data-path=""><a href="#test-set-differenti"><i class="fa fa-check"></i><b>3.2.2</b> Test Set Differenti</a></li>
<li class="chapter" data-level="3.2.3" data-path=""><a href="#test-set-uguali"><i class="fa fa-check"></i><b>3.2.3</b> Test Set Uguali</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path=""><a href="#regressione-lineare"><i class="fa fa-check"></i><b>3.3</b> Regressione lineare</a><ul>
<li class="chapter" data-level="3.3.1" data-path=""><a href="#critica"><i class="fa fa-check"></i><b>3.3.1</b> Critica</a></li>
<li class="chapter" data-level="3.3.2" data-path=""><a href="#valutazione"><i class="fa fa-check"></i><b>3.3.2</b> Valutazione</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path=""><a href="#class-imbalance-problem-feature-selection-and-non-binary-class"><i class="fa fa-check"></i><b>4</b> Class Imbalance Problem, Feature Selection and Non Binary Class</a><ul>
<li class="chapter" data-level="4.1" data-path=""><a href="#class-imbalance-problem"><i class="fa fa-check"></i><b>4.1</b> Class Imbalance Problem</a></li>
<li class="chapter" data-level="4.2" data-path=""><a href="#counting-the-cost"><i class="fa fa-check"></i><b>4.2</b> Counting the Cost</a><ul>
<li class="chapter" data-level="4.2.1" data-path=""><a href="#cumulative-gains"><i class="fa fa-check"></i><b>4.2.1</b> Cumulative Gains</a></li>
<li class="chapter" data-level="4.2.2" data-path=""><a href="#lift-chart"><i class="fa fa-check"></i><b>4.2.2</b> Lift Chart</a></li>
<li class="chapter" data-level="4.2.3" data-path=""><a href="#roc-curve"><i class="fa fa-check"></i><b>4.2.3</b> ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path=""><a href="#feature-selection"><i class="fa fa-check"></i><b>4.3</b> Feature Selection</a></li>
<li class="chapter" data-level="4.4" data-path=""><a href="#train-validation-test-and-feature-selection"><i class="fa fa-check"></i><b>4.4</b> Train, Validation, Test and Feature Selection</a></li>
<li class="chapter" data-level="4.5" data-path=""><a href="#non-binary-classification"><i class="fa fa-check"></i><b>4.5</b> Non Binary Classification</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path=""><a href="#clustering"><i class="fa fa-check"></i><b>5</b> Clustering</a><ul>
<li class="chapter" data-level="5.1" data-path=""><a href="#tipologie-di-cluster"><i class="fa fa-check"></i><b>5.1</b> Tipologie di Cluster</a></li>
<li class="chapter" data-level="5.2" data-path=""><a href="#prossimità"><i class="fa fa-check"></i><b>5.2</b> Prossimità</a><ul>
<li class="chapter" data-level="5.2.1" data-path=""><a href="#misure-di-prossimità"><i class="fa fa-check"></i><b>5.2.1</b> Misure di Prossimità</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path=""><a href="#clustering-evaluation"><i class="fa fa-check"></i><b>6</b> Clustering Evaluation</a><ul>
<li class="chapter" data-level="6.1" data-path=""><a href="#misure-di-valutazione"><i class="fa fa-check"></i><b>6.1</b> Misure di Valutazione</a><ul>
<li class="chapter" data-level="6.1.1" data-path=""><a href="#external-measure"><i class="fa fa-check"></i><b>6.1.1</b> External Measure</a></li>
<li class="chapter" data-level="6.1.2" data-path=""><a href="#internal-measure"><i class="fa fa-check"></i><b>6.1.2</b> Internal Measure</a></li>
<li class="chapter" data-level="6.1.3" data-path=""><a href="#relative-measure"><i class="fa fa-check"></i><b>6.1.3</b> Relative Measure</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path=""><a href="#validity-paradigm"><i class="fa fa-check"></i><b>6.2</b> Validity Paradigm</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path=""><a href="#association-analysis"><i class="fa fa-check"></i><b>7</b> Association Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path=""><a href="#valutazione-1"><i class="fa fa-check"></i><b>7.1</b> Valutazione</a></li>
</ul></li>
<li class="divider"></li>
<li><a href = "https://github.com/rstudio/bookdown" target = "blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Appunti - Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Appunti - Machine Learning</h1>
<p class="author"><em>Alberto Filosa</em></p>
<p class="date"><em>30/6/2020</em></p>
</div>
<div style="page-break-after: always;"></div>
<div id="data" class="section level1">
<h1><span class="header-section-number">1</span> Data</h1>
<p>In questo capitolo si tratteranno argomenti riguardanti la tipologia, il modo di esplorare, di valutare e come agire sui Missing Data e come fare pre-processing sui dati.
Esistono diversi tipi di dati:</p>
<ul>
<li><em>Categoriale</em> (quantitativa):
<ul>
<li>Nominale: i valori sono solo nomi differenti e fornisce informazioni solo sulla distinzione di un livello da un altro;</li>
<li>Ordinale: i valori sono ordinati mediante una scala;</li>
</ul></li>
<li><em>Numerica</em> (quantitativa):
<ul>
<li>Intervallare: la differenza tra valori è significativo;</li>
<li>Rapporti: sia la differenza che il rapporto sono significativi.</li>
</ul></li>
</ul>
<p>Una variabile può essere:</p>
<ul>
<li><em>Discreta</em>, un valore finito o contabile. Essa può essere:
<ul>
<li>Categoriale;</li>
<li>Numerica;</li>
<li>Binaria;</li>
</ul></li>
<li><em>Continua</em>, un valore appartenente all’insieme dei numeri Reali.</li>
</ul>
<div id="exploration" class="section level2">
<h2><span class="header-section-number">1.1</span> Exploration</h2>
<p>Esistono diversi modi per descrivere le statistiche relative ad un dataset:</p>
<ul>
<li>Media;</li>
<li>Moda;</li>
<li>Mediana;</li>
<li>Quantile e Percentile;</li>
<li>Range e Range Interquartile;</li>
<li>Varianza e Deviazione Standard;</li>
<li>Matrice di Varianze-Covarianze;</li>
<li>Coefficiente di Correlazione Lineare.</li>
</ul>
<p>Per la visualizzazione grafica si possono utilizzare sia istogrammi che boxplot.</p>
</div>
<div id="missing-replacement" class="section level2">
<h2><span class="header-section-number">1.2</span> Missing Replacement</h2>
<p>Molteo spesso sono presenti all’interno di un dataset dei <em>Missing Values</em>; i motivi possono essere molteplici:</p>
<ul>
<li>I valori non sono misurabili;</li>
<li>I valori non sono rilevanti alla prima collezione dei dati;</li>
<li>Si hanno degli errori di salvataggio del dataset;</li>
<li>I valori sono inconsistenti rispetto alle altre variabili.</li>
</ul>
<p>Bisogna ricordare che è molto importante risolvere questo tipo di problemi in modo da ottenere risultati robusti.
Esistono diversi modi per lavorare sui valori mancanti:</p>
<ul>
<li>Rimuovere il record se è presente un valore mancante;</li>
<li>Imputare manualmente il valore mancante (<strong>NON consigliato</strong>);</li>
<li>Usare una costante globale;</li>
<li>Usare la moda per sostituire il valore mancante;</li>
<li>Usare la media;</li>
<li>Usare la media condizionata, ovvero la media di righe che hanno lo stesso valore di un attributo;</li>
<li>Inserire il valore più probabile attraverso una semplice regressione lineare oppure utilizzando anche modelli più complessi.</li>
</ul>
</div>
<div id="pre-processing" class="section level2">
<h2><span class="header-section-number">1.3</span> Pre-Processing</h2>
<p>Il <em>Pre-Processing</em> è un’area di strategia e di tecniche che consente di lavorare con i dati, per rendere le successive analisi più efficienti.</p>
<p>L’<strong><em>Aggregazione</em></strong> consiste nel combinare due o più record in una singola riga utilizzando la media o la somma dei valori. Se la variabile è categoriale, si aggregano come una tupla.
I vantaggi del suo utilizzo sono molteplici:</p>
<ul>
<li>Il dataset è più compatto e pesa meno dal punto di vista computazionale;</li>
<li>Si ha un livello di dettaglio più generale dei dati;</li>
<li>Riduce la varianza, aumentando l’efficienza, ma diminuendo l’interesse nei dettagli dei dati.</li>
</ul>
<p>Il <strong><em>Campionamento</em></strong> consiste nel selezionare diversi record casualmente, utilizzando meno righe.
Il campione, però, deve essere rappresentativo, ovvero le stesse proprietà del dataset originale, ad esempio, confrontando la media del campione con quello della popolazione.
Esistono due principali modalità di campionamento:</p>
<ul>
<li><strong><em>C</em></strong>ampionamento <strong><em>C</em></strong>asuale <strong><em>S</em></strong>emplice (CCS): ogni riga del dataset ha la stessa probabilità di essere estratta nel campione. Essa si divide in estrazione:
<ul>
<li>Con Reinserimento (CR);</li>
<li>Senza Reinserimento (SR).</li>
</ul></li>
<li><strong><em>C</em></strong>ampionamento <strong><em>C</em></strong>asuale <strong><em>St</em></strong>ratificato: utile per variabili qualitative, si compie un campionamento in base ai livelli della variabile considerata. Il campionamento può essere:
<ul>
<li>Proporzionale, in base alla percentuale di stratificazione di una variabile;</li>
<li>Numero equo per ogni stratificazione della variabile.</li>
</ul></li>
</ul>
<p>Una volta selezionata la tipologia di campionamento, si sceglie la grandezza del campione: un ampio campione aumenta la probabilità di rappresentatività, andando ad eliminare però numerosi vantaggi del campionamento.</p>
<p>Molte volte capita di analizzare dataset con molteplici attributi; è possibile e consigliato ridurre la <strong><em>Dimensionalità</em></strong> del dataset.
I principali vantaggi di questa modalità di pre-processing sono molteplici:</p>
<ul>
<li>Gli algoritmi lavorano meglio con bassa dimensionalità;</li>
<li>Aumenta l’interpretabilità del modello;</li>
<li>La rappresentazione grafica è più facile;</li>
<li>Lo spazio di memoria ed il tempo di processo sono ridotti.</li>
</ul>
<p>Aumentando la dimensionalità, l’analisi di dati diventa più complicata, quindi non sempre è efficiente un dataset molto grande. Esistono diverse tecniche di riduzione della dimensionalità, le più importanti sono:</p>
<ol style="list-style-type: decimal">
<li><strong><em>P</em></strong>rincipal <strong><em>C</em></strong>omponent <strong><em>A</em></strong>nalysis (PCA): l’obiettivo è quello di trovare nuovi attributi che siano una combinazione lineare degli attributi originali, ortogonali tra di loro e che catturano la massima variabilità dei dati;</li>
<li><strong><em>S</em></strong>ingular <strong><em>V</em></strong>alue <strong><em>D</em></strong>ecomposition (SVD): tecnica alternativa alla PCA, è usata per la riduzione della dimensionalità.</li>
</ol>
<p>Talvolta è utile trasformare variabili discrete/continue in binarie; il processo è chiamato <strong><em>Binarizzazione</em></strong>: si associa il singolo fattore ad un valore (se ordinale, l’ordine deve essere mantenuto) e si converte il valore ad una variabile dicotoma, come <span class="math inline">\(s=\log_2k\)</span>.
Alcune volte è necessario inserire una variabile binaria per ogni valore della variabile categoriale iniziale.</p>
<p>Utilizzata solitamente per analisi di classificazione/associazione, la <strong><em>Discretizzazione</em></strong> divide in intervalli la variabile iniziale.
La discretizzazione può essere:</p>
<ul>
<li><em>Non supervisionata</em>: non si prendono in considerazione ulteriori attributi del dataset, ma si specifica autonomamente il numero di intervalli e i punti di divisione. Gli intervalli possono avere stessa frequenza o stessa ampiezza;</li>
<li><em>Supervisionata</em>: si prendono in considerazione attributi del dataset e si sceglie una funzione obiettivo, come l’Entropia, per valutare il massimo livello di purezza del singolo intervallo (oppure il minimo livello di entropia).</li>
</ul>
<p>In alcuni casi, le variabili categoriali potrebbero avere troppi livelli.
Se la variabile categoriale è ordinale, allora si usa la tecnica simile alle variabili continue per ridurre la dimensionalità.
Se nominale, allora si crea una nuova variabile in base al tipo di modalità di raggruppamento; se non è possibile, si usano metodi algoritmici.</p>
<p>Infine, sulle variabili esplicative è possibile applicare delle <strong><em>Trasformazioni</em></strong> in modo da crearne delle nuove attraverso semplici funzioni matematiche, come la funzione logaritmica, oppure tramite una normalizzazione o standardizzazione della stessa.</p>
</div>
</div>
<div id="classification" class="section level1">
<h1><span class="header-section-number">2</span> Classification</h1>
<p>I <em>Modelli di Classificazione</em> hanno l’obiettivo di prevedere un particolare attributo (per esempio prevedere se un utente rimarrà nella compagnia telefonica) presente in un dataset.
Il modello presenta degli ingressi, chiamate variabili di <em>input</em> (in questo caso il dataset di partenza) ed una uscita, la previsione della variabile categoriale chiamata <em>output</em>.
Inoltre, risolve il problema di classificazione per una osservazione ed è utile per:</p>
<ul>
<li>Modelli descrittivi, per distinguere oggetti da classi differenti;</li>
<li>Modelli predittivi, per prevedere la classe di un nuovo record dato un insieme di valori.</li>
</ul>
<p>La tecnica di classificazione è un approccio sistematico per costruire un modello che classifica una osservazione a partire da un dataset.
Si seleziona una parte dei dati per costruire il dataset di <strong>training</strong>, su cui il modello di classificazione imparerà il metodo di classificazione.
Successivamente, si applica il modello di classificazione sul dataset di <strong>test</strong>.
L’output del learning model si chiama <em>inducer</em> e l’istanza del modello verrà utilizzata per la previsione di classificazione sul dataset di test.</p>
<p>Per misurare le performance del modello si utilizza la matrice di confusione: sulle righe si hanno i valori reali della classe (Yes/No, 1/0, +1/-1, ecc.), mentre sulle colonne il valore previsto dal modello.
Esistono 4 possibili combinazioni:</p>
<ul>
<li><em>True Negative</em> (TN): il numero di record nei quali l’effettivo valore della classe è negativo ed il modello lo classifica come negativo;</li>
<li><em>False Negative</em> (FN): il numero di record nei quali l’effettivo valore della classe è negativo, ma il modello lo classifica come positivo;</li>
<li><em>True Positive</em> (TP): il numero di record nei quali l’effettivo valore della classe è positivo ed il modello lo classifica come positivo;</li>
<li><em>False Positive</em> (FP): il numero di record nei quali l’effettivo valore della classe è positivo, ma il modello lo classifica come negativo.</li>
</ul>
<p>La metrica di performance del modello è chiamata <strong>Accuracy</strong>, definita come il rapporto della somma della diagonale principale e la cardinalità del dataset:</p>
<p><span class="math display">\[Accuracy = \frac{TN+TP}{TN+FN+FP+TP}\]</span></p>
<p>L’errore di performance è definita come il reciproco della accuracy:</p>
<p><span class="math display">\[Error = 1 - Accuracy\]</span></p>
<div id="tecniche-di-classificazione" class="section level2">
<h2><span class="header-section-number">2.1</span> Tecniche di Classificazione</h2>
<p>Un tecnica di classificazione (<em>Classifier</em>) è un approccio sistematico per la costruzione di un modello di classificazione partendo da un dataset.
Esse possono essere divise in:</p>
<ul>
<li>Euristici (es: Decision Tree, Random Forest, Nearest Neighbor, ecc.);</li>
<li>Regression Based: si usa un parametro di probabilità (es: Logistic Regression);</li>
<li>Separation: si partiziona lo spazio delle variabili (es: Support Vector Machine, Artificial Neural Networks, ecc.);</li>
<li>Probabilistici: si usa la formula di Bayes e si prevedono le posterior (es: Naive Bayes, ecc.).</li>
</ul>
<div id="modelli-euristici" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Modelli Euristici</h3>
<p>Un <strong><em>Albero Decisionale</em></strong>, in inglese <em>Decision Tree</em>, descrive una struttura ad albero costituito in diversi nodi:</p>
<ul>
<li>Nodo radice, senza archi in entrata e 0 o più archi in uscita;</li>
<li>Nodo interni: con un solo arco in ingresso ed uno o più archi in uscita;</li>
<li>Nodo terminale (o nodo foglia), conun solo arco in entrata e nessuno in uscita.</li>
</ul>
<p>Ad ogni nodo è associata una soglia legata ad un attributo di colonna e a seconda del valore si sceglie il nodo di destra o sinistra.
L’albero decisionale può essere usato sia per variabili categoriali che numeriche.
Per dividere in modo ottimale i nodi si usano diverse misure, come l’<em>Entropia</em>, l’<em>Indice di Impurità di Gini</em> o l’<em>Errore di Classificazione</em>.</p>
<p>Si possono utilizzare anche split multipli, non solo binomiali, o anche in base al tipo di livello dell’attributo.
Il cambio di classificazione dove si modifica la linea di decisione è chiamata <em>Decision Boundary</em>.</p>
<p>La <strong><em>Regressione Logistica</em></strong> è un modello statistico nella quale si vuole prevedere la probabilità a posteriori della variabile risposta binomiale partendo da un insieme di variabili esplicative.
Indicato con <span class="math inline">\(w\)</span> il vettore dei parametri, si presentano le posterior del modello:</p>
<p><span class="math display">\[P(Y = 0|X = x) = \frac{1}{1 + e^{w \times x}}\]</span>
<span class="math display">\[P(Y = 1|X = x) = \frac{e^{w \times x}}{1 + e^{w \times x}}\]</span></p>
</div>
<div id="modelli-di-separation" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Modelli di Separation</h3>
<p>Il <strong><em>Support Vector Machine</em></strong> è un modello di classificazione robusto basato su algoritmi efficienti.
Dato un dataset di m righe dove si misurano due attributi, con <span class="math inline">\(\vec x_i \in R^2\)</span> e <span class="math inline">\(y_i \in (-1,+1)\)</span>:</p>
<p><span class="math display">\[D = {(\vec x_1, \vec y_1),...,(\vec x_m, \vec y_m)}\]</span></p>
<p>si possono separare due (nel caso generare più di due) istanze tramite la seguente equazione:
<span class="math display">\[\vec w \vec x + b = w_1 b_1 + w_2 b_2 + b = 0\]</span></p>
<p>La retta si può traslare o ruotare, ma per selezionare la miglior decision boundary si utilizza la retta che massimizza il margine tra le due classificazioni.
Il modello SVM svolge la seguente funzione:</p>
<p><span class="math display">\[h(x) =
  \begin{cases}
    +1 &amp; \quad
    \text{se  retta positiva} \\ 
    -1 &amp; \quad
    \text{altrimenti}
  \end{cases}\]</span></p>
<p>Allenare il margine lineare SVM consiste nel formulare e risolvere la seguente equazione:</p>
<p><span class="math display">\[min_{\vec w, h} \frac{1}{2} \vec w \times \vec w^t\]</span></p>
<p>con il seguente vincolo: <span class="math inline">\(y_i (\vec w_i \times \vec x_i + b) \geq 1\)</span> e <span class="math inline">\(\forall i = 1, ..., m\)</span></p>
<p>Tutto ciò avviene se l’insieme dei dati è linearmente separabile.
Se questo non è possibile, si introduce il concetto di formulazione del <em>Linear Soft-Margin</em> della SVM, aggiungendo un termine di penalizzazione alla equazione precedente:</p>
<p><span class="math display">\[min_{\vec w, b, \xi} \vec w \vec w^t + \Delta \sum_{i = 1}^m \xi_i\]</span></p>
<p>con vincoli:</p>
<ul>
<li><span class="math inline">\(\forall i = 1, ..., m: y_i(\vec w \vec x_i + b) \geq 1 - \xi_i\)</span>;</li>
<li><span class="math inline">\(\forall i = 1, ..., m: \xi_i \geq0\)</span>.</li>
</ul>
<p>Per migliorare la velocità delle SVM, si genera uno spazio, chiamato <em>Feature Space</em>, nella quale si mappa lo spazio <span class="math inline">\(X\)</span> in <span class="math inline">\(F\)</span>, trasformando le osservazioni rendendo le istanze linearmente separabili.
Così facendo, è possibile ottenere una retta che divide i punti in due classi traslandoli in una quantità pari a <span class="math inline">\(\Phi_i\)</span>.
La <em>linear decision boundary</em> che divide le due istanze nel feature space F ha la seguente equazione:</p>
<p><span class="math display">\[\vec w \Phi (\vec x) + b = 0\]</span></p>
<p>Allenare il margine non lineare SVM consiste nel formulare e risolvere la seguente equazione:</p>
<p><span class="math display">\[min_{\vec w, h} \frac{1}{2} \vec w \vec w^t\]</span></p>
<p>con i seguenti vincoli:</p>
<ul>
<li><span class="math inline">\(y_i \times (\vec w \Phi (\vec x_i) + b) \geq 1\)</span> e <span class="math inline">\(\forall i = 1,..., m\)</span></li>
</ul>
<p>La principale differenza tra queste algoritmi di separazione è che la Non linear SVM utilizza una trasformazione di <span class="math inline">\(X\)</span>, ottenendo <span class="math inline">\(\Phi(\vec X)\)</span>.
L’algoritmo di apprendimento della Non Linear SVM è il seguente:</p>
<p><span class="math display">\[K(\vec u, \vec v) = \Phi (\vec u) \times \Phi (\vec v)\]</span></p>
<p>con K una funzione di similarità ottenuta nello spazio delle variabili X e definita come funzione kernel.</p>
<p>Le <strong><em>Neural Network</em></strong> sono dei modelli molto avanzati ispirati dai neuroni biologici che costituiscono il cervello animale.
Un <strong><em>M</em></strong>ulti-<strong><em>L</em></strong>ayer <strong><em>P</em></strong>erceptron (MLP) consiste in un diverso numero neuroni artificiali che comunicano in modo unidirezionale, dalle variabili di input <span class="math inline">\(X\)</span> all’attributo di classe.
In generale, si calcola come la combinazione lineare tra le variabili di input meno la soglia (treshold):</p>
<p><span class="math display">\[y_j = f(\sum_{i = 1}^n w_{ij} \times x_i - \theta_j) = f(z_j - \theta_j)\]</span></p>
<p>Possibili funzioni di trasferimento sono:</p>
<ul>
<li>Trasformazione iperbolica: <span class="math inline">\(f(z) = \frac{e^{(z)} - e^{(-z)}}{e^{(z)} + e^{(-z)}}\)</span></li>
<li>Trasformazione logistica: <span class="math inline">\(f(z) = \frac{1}{1 + e^{(-z)}}\)</span></li>
</ul>
<p>I MLP sono costituiti da diversi neuroni:</p>
<ul>
<li>Neuroni di input, associato alle covariate;</li>
<li>Neuroni nascosti;</li>
<li>Neuroni di output, associato all’attributo di classe.</li>
</ul>
<p>Ogni neurone di input è connesso in modo unidirezionale ai neuroni nascosti, propagando il segnale dal layer di input a quello nascosto.
Quando tutti i neuroni del layer nascosto ricevono il segnale dai layer di input, il segnale è mandato a quello di output.
Tuttavia, è possibile anche avere più di un layer nascosto: il primo layer manda tutti i segnali al secondo che si attiveranno.
Alla fine, quest’ultimo manda dei segnali al neurone di output.</p>
<p>L’obiettivo principale del MLP è quello di identificare il numero di layer nascosti ed i relativi neuroni nascosti.
MLP è un modello molto complesso ed esistono diverse misure di ottimizzazione, ma non è possibile determinare il minimo assoluto per ogni layer.</p>
<p>Esistono diverse architetture del MLP, con un numero diverso di layer nascosti e numero diverso di neuroni nascosti.
Bisogna ricordare che non è possibile avere degli archi che vanno da uno strato più basso ad uno più alto.</p>
</div>
<div id="modelli-probabilistici" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Modelli Probabilistici</h3>
<p>I modelli probabilistici usano la formula di Bayes per prevedere le posterior.</p>
<p>Il <strong><em>Bayes Classifier</em></strong> è un classificatore probabilistico che risolve il problema di classificazione calcolando la probabilità condizionata <span class="math inline">\(P(Y | \vec X) = \frac{P(\vec X | Y) P(Y)}{P(\vec X)}\)</span>
dove:</p>
<ul>
<li><span class="math inline">\(P(Y)\)</span> è la probabilità a priori dell’attributo della classe;</li>
<li><span class="math inline">\(P(\vec X|Y)\)</span> è la verosimiglianza delle covariate dato l’attributo della classe;</li>
<li><span class="math inline">\(P(\vec X)\)</span> è la probabilità dell’evidenza (osservazione di una prova);</li>
<li><span class="math inline">\(P(Y|\vec X)\)</span> è la posterior dell’attributo della classe date le covariate.</li>
</ul>
<p>Dopo aver calcolato le posterior, bisogna decidere a quale label appartiene l’osservazione.
Si utilizza la decisione di massima probabilità, nella quale si associa la label al massimo valore della posterior della singola osservazione.
Assumendo <span class="math inline">\(n\)</span> covariate binarie e una risposta binaria, bisogna tenere in considerazione che:</p>
<ul>
<li><span class="math inline">\(\theta_{ki}=P(\vec X=x_k|Y=y_i)\)</span>;</li>
<li><span class="math inline">\(k \in (1,...,2^n)\)</span>;</li>
<li><span class="math inline">\(y_i \in \{-1,+1\}\)</span>.</li>
</ul>
<p>Il <strong><em>Naive Bayes</em></strong> è un modello probabilistico che dati tre attributi <span class="math inline">\(X\)</span>,<span class="math inline">\(Y\)</span>,<span class="math inline">\(Z\)</span> è possibile affermare che <span class="math inline">\(X\)</span> è condizionalmente indipendente da <span class="math inline">\(Y\)</span> dato <span class="math inline">\(Z\)</span> se e solo se la probabilità di <span class="math inline">\(X\)</span> è indipendente dal valore dell’attributo <span class="math inline">\(Y\)</span> quando il valore di <span class="math inline">\(Z\)</span> è noto:</p>
<p><span class="math display">\[P(X = x_i | Y = y_j, Z = z_k) = P(X = x_i | Z = z_k)\]</span></p>
<p>L’indipendenza condizionata di <span class="math inline">\(n\)</span> covariate dato l’attributo di classe riduce il numero di parametri da svolgere.
Il modello Naive Bayes assume questa indipendenza ed è possibile calcolare le posterior dell’attributo di classe date le covariate secondo la seguente formula:</p>
<p><span class="math display">\[P(X_1, X_2, ..., X_n | Y) = \prod_{i = 1}^n P(X_i | Y))\]</span></p>
<p>Il numero di parametri <span class="math inline">\(k\)</span> passa da <span class="math inline">\(k(k^n - 1)\)</span> a <span class="math inline">\(kn\)</span>. Il classificatore Naive Bayes calcola le posterior dell’attributo di classe secondo la formula:</p>
<p><span class="math display">\[P(Y = y_k | X_1, ..., X_n) = \frac{P(Y = y_k) \prod_{i}^n P(X_i | Y = y_k)}{\sum_j^k P(Y = y_k) \prod_{i}^n P(X_i | Y = y_j)}\]</span></p>
<p>Il record <span class="math inline">\((X_1, X_2, ..., X_n)\)</span> è etichettato come il valore della classe che massimizza le posterior:</p>
<p><span class="math display">\[\max_{y_k} P(Y = y_k | X_1, X_2, ..., X_n)\]</span></p>
<p>Bisogna considerare che il classificatore Naive Bayes è utilizzato anche con attributi numerici: ogni attributo numerico è associato ad una classe di probabilità condizionale.
Ogni attributo numerico è associato alla probabilità di classe condizionata, calcolata con la seguente formula:</p>
<p><span class="math display">\[P(X_i = x_i | Y = y_k) = \frac{1}{\sqrt{2 \pi} \sigma_{ik}} \times e^{-\frac{(x_i - \mu_{ik})^2}{2 \sigma_{ik}^2}}\]</span></p>
<p>con parametri:</p>
<ul>
<li><span class="math inline">\(\mu_{ik} = E[X_i | Y = y_k]\)</span>;</li>
<li><span class="math inline">\(\sigma_{ik}^2 = E[(X_i - \mu_{ik})^2 | Y = y_k]\)</span>.</li>
</ul>
<p>Il classificatore Naive Bayes è generalizzato dal <strong><em>Bayesian Network</em></strong> che rende meno drastico l’assunzione d’indipendenza incondizionata, servendosi della <em>sparsity</em>.
L’attributo di classe è ancora associato al nodo di root <span class="math inline">\(Y\)</span>, mentre gli attributi esplicativi sono associati non solo alla <span class="math inline">\(Y\)</span>, ma anche agli stessi attributi di classe.
Bisogna considerare, però, che non sono ammessi cicli.</p>
<p>Questa generalizzazione mantiene le proprie dipendenze tra le covariate che non assumono più l’indipendenza dato l’attributo di classe <span class="math inline">\(Y\)</span>.
A livello di classificazione, il vantaggio è che funziona perfettamente anche con <em>NA</em> di input.</p>
<p>Un particolare modello è il <strong><em>Tree-Augmented Naive Bayes</em></strong>, che permette di avere al più un altro nodo genitore rimuovendo il nodo di classe.
Inoltre, effettua model selection calcolando gli attributi più interessanti.</p>
</div>
</div>
</div>
<div id="performance-evaluation" class="section level1">
<h1><span class="header-section-number">3</span> Performance Evaluation</h1>
<p>L’<em>Accuracy</em> del modello non sempre è una modalità sufficiente per confrontare l’efficienza del modello.
Gli errori compiuti su un modello di classificazione possono essere:</p>
<ul>
<li><em>Errore di Training</em>: il numero di record del training classificate in modo errato;</li>
<li><em>Errore di Generalizzazione</em>: errore previsto nel dataset di test.</li>
</ul>
<p>Un buon modello di classificazione non solo deve classificare bene il dataset di training, ma anche quello di test; in particolare, devono avere sia un basso training error che un basso errore di generalizzazione.</p>
<p>Un modello che classifica troppo bene il dataset di training può avere un basso errore di generalizzazione rispetto ad un alto errore di Training.
Questo fenomeno è chiamato <strong><em>overfitting</em></strong> ed avviene quando un modello ha una performance troppo elevata nel dataset di training, ma generalizza male quello di Test.
Il fenomeno opposto è detto <strong><em>underfitting</em></strong>, nella quale un modello commette un alto errore di classificazione sia sui dati di training che sui dati di test.
Molto probabilmente il modello è poco complesso rispetto ai dati e non classifica bene le osservazioni.</p>
<div id="misure-di-performance" class="section level2">
<h2><span class="header-section-number">3.1</span> Misure di performance</h2>
<p>L’analisi di classificazione consiste nell’utilizzare diversi modelli di classificazione associati a parametri valutati e successivamente nel confrontarli per osservare quale tra quelli utilizzati è il più efficiente.
I modelli di classificazione sono confrontati in diversi termini.</p>
<p>L’<strong><em>Accuratezza</em></strong> misura la capacità del modello di classificazione di predire in modo affidabile nuovi record.
Inoltre, permette di selezionare e garantire le performance migliori sui nuovi dati. Successivamente verranno considerate le seguenti notazioni:</p>
<ul>
<li><span class="math inline">\(D_T\)</span>, dati di training (con <span class="math inline">\(t\)</span> righe);</li>
<li><span class="math inline">\(D_{Ts}\)</span>, dati di test (con <span class="math inline">\(v\)</span> righe).</li>
</ul>
<p>Un buon indicatore di accuracy è misurato dalla percentuale di righe classificate in modo corretto da <span class="math inline">\(D_{Ts}\)</span>.
Sia <span class="math inline">\(y_i\)</span> il valore associato all’istanza <span class="math inline">\(x \in D_{Ts}\)</span>, definito come il valore della classe predetto dal modello.
Si introduce la funzione di perdita, chiamata in inglese <em>Loss function</em>:</p>
<p><span class="math display">\[L(y_i, f(\vec{x_i})) =
  \begin{cases}
    0 &amp; \quad
    y_i = f(\vec{x_i}) \\ 
    1 &amp; \quad
    y_i \neq f(\vec{x_i})
  \end{cases}\]</span></p>
<p>L’accuracy è calcolata nel nel seguente modo:</p>
<p><span class="math display">\[acc(D_{Ts}) = 1 - \frac{1}{v} \sum_{n = 1}^{v} L(y_i, f(\vec{x_i}))\]</span></p>
<p>In alcuni casi è preferibile utilizzare l’errore dell’accuracy:
<span class="math display">\[Err(D_{Ts})=1-acc(D_{Ts})=\frac{1}{v}\sum_{n=1}^{v} L(y_i, f(\vec{x_i})\]</span></p>
<p>Gli algoritmi di classificazione differiscono dal tempo di apprendimento e dallo spazio di memoria.
Quando un classificatore richiede un alto tempo di apprendimento e/o uno spazio di memoria elevato è consigliato compiere un campionamento del dataset originale.</p>
<p>Un modello è considerato <strong><em>robusto</em></strong> nel caso in cui non sono presenti outliers, valori mancanti ed alcuna variazione tra i dati di test e di training.</p>
<p>Un modello è considerato <strong><em>scalabile</em></strong> quando il modello è capace di apprendere enormi quantità di dati. La scalabilità è strettamente legata alla velocità di apprendimento).</p>
<p>Un modello è definito <strong><em>interpretabile</em></strong> quando il problema di classificazione è risolto e non si limita ad avere un buon livello di accuracy.
Il modello di classificazione deve essere semplice e chiaro nella comprensione di un esperto di dominio, che molte volte non conosce la statistica.</p>
<p>Esistono diverse procedure per la valutazione delle performance di un modello di classificazione:</p>
<p>La procedura <strong><em>Holdout</em></strong> divide il dataset originale con una semplice procedura di CCS, suggerendo la divisione in 2/3 per il dataset di training, per far apprendere il modello di classificazione ed ottenere un inducer, e 1/3 per il dataset di test, su cui verrà misurata l’accuracy del modello.
Essa consiste nel limitare l’uso dei dati per far apprendere il classificatore. L’accuratezza stimata dipende dalla scelta del dataset di test, per non incorrere in fenomeni di over/under-fitting.</p>
<p>Una stima più robusta alla comune Holdout è chiamata <strong><em>Iterated Holdout</em></strong>, che consiste nell’iterare R volte il metodo descritto in precedenza.
Per ogni interazione si estrae un campione <span class="math inline">\(D_{Tr}\)</span> composto da t righe, ottenendo <span class="math inline">\(D_{Ts_r}=D-D_{Tr}\)</span>.
L’accuratezza del classificatore è stimata dalla media dei valori di accuracy di ogni campionamento:</p>
<p><span class="math display">\[acc = \frac{1}{R} \times \sum_{n = 1}^{R} acc(D_{Ts_r})\]</span></p>
<p>In questo modo, è possibile ridurre la varianza associata alla stima, ma non permette di controllare il numero di volte in cui il dato record è contenuto nel dataset di training e di test.</p>
<p>La <strong><em>Cross Validation</em></strong> è un altro metodo robusto di valutazione delle performance del modello.
Il dataset <span class="math inline">\(D\)</span> viene diviso in <span class="math inline">\(k\)</span> sotto-categorie, contenendo diversi piccoli dataset <span class="math inline">\(D_1, D_2, ..., D_k\)</span>.
Successivamente, si compiono k volte apprendimenti sul dataset di test; alla k-esima iterazione, si ottiene il seguente dataset di training:</p>
<p><span class="math display">\[D_{T_k} = \{D_1, ..., D_{k-1}, D_{k+1}, ..., D_k\}\]</span></p>
<p>Il suo complemento <span class="math inline">\(D_k\)</span> è usato come dataset di test.
L’algoritmo di classificazione procede in k fasi di training.
Per ottenere l’accuracy, si compie la media di ogni k:</p>
<p><span class="math display">\[acc = \frac{1}{K} \times \sum_{n = 1}^{K} acc(D_k)\]</span></p>
<p>Si possono scegliere diversi valori del parametro K (di solito sono 3,5,10).
Comunque, è necessario tenere in considerazione che ogni partizione del dataset deve contenere la stessa proporzione dei possibili valori dell’attributo di classe.
Se differiscono molto tra di loro, è consigliato utilizzare un campionamento stratificato.</p>
</div>
<div id="comparing-classifiers" class="section level2">
<h2><span class="header-section-number">3.2</span> Comparing Classifiers</h2>
<p>Dopo aver costruito diversi modelli di classificazione, bisogna stimare quale sia il migliore tra tutti; il concetto non è facile da definire, ma un confronto iniziale è comparare le accuracy dei modelli.
Molte volte è utile comparare le performance dei modelli per determinare quale sia il migliore, bisogna ricordare che il calcolo della accuracy considerando differenza dei record non è statisticamente rilevante.</p>
<p>Si presentano perciò due problemi:</p>
<ol style="list-style-type: decimal">
<li>Intervalli di Confidenza dell’Accuracy del modello;</li>
<li>Differenza di Accuracy dei modelli.</li>
</ol>
<div id="intervallo-di-confidenza" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Intervallo di Confidenza</h3>
<p>Si considera il Test set <span class="math inline">\(D_N\)</span> con <span class="math inline">\(N\)</span> il numero di record.
Sia <span class="math inline">\(X \sim Bi(Np, Np (1-p))\)</span> il numero di previsioni corrette e <span class="math inline">\(p\)</span> la vera accuratezza del modello.
L’accuratezza empirica è calcolata come <span class="math inline">\(acc = \frac{X}{N}\)</span>, con <span class="math inline">\(X \sim Bi(p, \frac{p(1-p)}{N})\)</span>.
La distribuzione Binomiale è usata per stimare l’IC per l’accuracy approssimandola ad una N, calcolata nel seguente modo:</p>
<p><span class="math display">\[P(-z_{1 - \alpha / 2} &lt; \frac{acc - p}{\sqrt{p (1 - p) / N}} &lt; z_{1 - \alpha / 2}) = 1 - \alpha\]</span></p>
<p>Questo procedimento è possibile solamente ripetendo l’esperimento n volte e tra loro indipendenti.</p>
<p>L’IC della accuracy sarà:</p>
<p><span class="math display">\[\frac{acc+\frac{z^2_{1-\alpha/2}}{2N} \pm z_{1-\alpha/2}\times\sqrt{\frac{acc}{N}-\frac{acc}{N^2}+\frac{z^2_{1-\alpha/2}}{4N^2}}}{1+z^2_{1-\alpha/2/N}}\]</span></p>
<p>All’aumentare della dimensione del campione, l’ampiezza dell’IC diminuirà e quindi la stima sarà più precisa.</p>
</div>
<div id="test-set-differenti" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Test Set Differenti</h3>
<p>Si considerano due modelli di classificazione indipendenti:</p>
<ul>
<li><span class="math inline">\(M_1\)</span> con un test set <span class="math inline">\(D_1\)</span> contenente <span class="math inline">\(n_1\)</span> osservazioni ed un errore <span class="math inline">\(e_1\)</span>;</li>
<li><span class="math inline">\(M_2\)</span> con un test set <span class="math inline">\(D_2\)</span> contenente <span class="math inline">\(n_2\)</span> osservazioni ed un errore <span class="math inline">\(e_2\)</span>.</li>
</ul>
<p>La differenza in termini di errore, <span class="math inline">\(d=e_1 - e_2\)</span>, è statisticamente significativo?
Si considerano <span class="math inline">\(n_1\)</span> e <span class="math inline">\(n_2\)</span> sufficientemente grandi e quindi che <span class="math inline">\(e_1\)</span>, <span class="math inline">\(e_2\)</span> siano statisticamente distribuiti come una N; perciò, anche <span class="math inline">\(d \sim N(d_t,\sigma^2_d=\frac{e_1(1-e_1)}{n_1}+\frac{e_2(1-e_2)}{n_2})\)</span>.
L’IC sarà:</p>
<p><span class="math display">\[IC_{d_t}=(d-z_{1-\alpha/2}\times \sigma_d,d+z_{1-\alpha/2}\times \sigma_d )\]</span></p>
<p>Si prendono in considerazione tre possibilità:</p>
<ul>
<li>Se IC contiene 0, allora i due classificatori non sono significativamente differenti in termini di errore con livello di confidenza <span class="math inline">\(\alpha\)</span>;</li>
<li>Se l’estremo superiore è negativo, si preferisce il modello <span class="math inline">\(M_1\)</span> rispetto a <span class="math inline">\(M_2\)</span> a livello di classificazione;</li>
<li>Se l’estremo inferiore è positivo, si preferisce il modello <span class="math inline">\(M_2\)</span> rispetto a <span class="math inline">\(M_1\)</span> a livello di classificazione.</li>
</ul>
</div>
<div id="test-set-uguali" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Test Set Uguali</h3>
<p>Si considera la situazione in cui si comparano i due modelli usando la procedura di cross-validazione K-fold, perciò il dataset D è diviso in k sottogruppi, creando <span class="math inline">\(D_1, D_2, ..., D_k\)</span> dataset.
Applicando la tecnica di classificazione per costruire <span class="math inline">\(M_1\)</span> e <span class="math inline">\(M_2\)</span> dalle <span class="math inline">\(k - 1\)</span> partizioni e testarli sulla rimanente, si applica questo step k volte, usando ogni volta partizioni differenti del test set.
Si considerano i seguenti modelli:</p>
<ul>
<li><span class="math inline">\(M_{1k}\)</span>, il modello inducer del modello <span class="math inline">\(M_1\)</span> ottenuto alla k-esima iterazione;</li>
<li><span class="math inline">\(M_{2k}\)</span>, il modello inducer del modello <span class="math inline">\(M_2\)</span> ottenuto alla k-esima iterazione.</li>
</ul>
<p>Su ogni partizione dei dati, si conduce il test sullo stesso test set.
Si considerano i seguenti errori:</p>
<ul>
<li><span class="math inline">\(e_{1k}\)</span> l’errore di <span class="math inline">\(M_{1k}\)</span>;</li>
<li><span class="math inline">\(e_{2k}\)</span> l’errore di <span class="math inline">\(M_{2k}\)</span>.</li>
</ul>
<p>La differenza <span class="math inline">\(d_k = e_{1k} - e_{2k}\)</span> alla k-esima iterazione è distribuita come <span class="math inline">\(N(d_t^{cv}, \sigma^{2}_{cv})\)</span>.
La varianza totale è stimata usando la seguente formula:</p>
<p><span class="math display">\[\hat \sigma^2_{d_{cv}} = \frac{\sum_{k = 1}^K (d_k - \overline d)^2}{K(K-1)}\]</span></p>
<p>con <span class="math inline">\(\overline d = \frac{1}{K} \sum^K_{k = 1}d_k\)</span>.
Si utilizza la distribuzione t-Student per calcolare l’IC del valore medio di <span class="math inline">\(d_t^{cv}\)</span>:</p>
<p><span class="math display">\[IC=(\overline d-t_{1-\alpha/2}^{k-1} \times \hat \sigma_{d_{cv}},\overline d+t_{1-\alpha/2}^{k-1} \times \hat \sigma_{d_{cv}}) \]</span></p>
<p>Si compiono le considerazioni precedentemente svolte.</p>
</div>
</div>
<div id="regressione-lineare" class="section level2">
<h2><span class="header-section-number">3.3</span> Regressione lineare</h2>
<p>La variabile dipendente (o di risposta) in un modello di regressione lineare è una variabile continua.
Il modello spiega una variabile dall’insieme degli attributi del dataset.
Si cerca una funzione:
<span class="math display">\[\begin{align*}
  f &amp;: R^k \rightarrow R \\
  \widehat{Y} &amp;= f(\underline{X}) + \epsilon
\end{align*}\]</span>
a cui si aggiunge un errore (o residuo) <span class="math inline">\(\epsilon\)</span> che rappresenta lo scarto del modello, dovuto a incertezza o ignoranza della formula reale. 
Un modello di regressione lineare è una funzione lineare di una matrice (del disegno) di valori <span class="math inline">\(\underline{X}\)</span> pesata con un vettore <span class="math inline">\(\underline{w}\)</span>.
Se la matrice del disegno è composta da una sola variabile indipendente, il modello è detto <em>modello lineare semplice</em>: non ha funzioni pratiche ma è interessante dal punto di vista teorico perché presenta le stesse problematiche dei modelli multivariati, polinomiali e con componenti rettangolari. 
L’obiettivo è minimizzare l’errore standard commesso nel prevedere <span class="math inline">\(y\)</span> tramite la funzione <span class="math inline">\(f\)</span>:
<span class="math display">\[\begin{align*}
  SSE &amp;= \sum^m_{i=1}{e^2_i} \\
      &amp;= \sum^m_{i=1}{[y_i - f(\underline{X})]^2} \\
      &amp;= \sum^m_{i=1}{[y_i - x_i w_i - b]^2}
\end{align*}\]</span>
Aggiungere variabili indipendenti non modifica il ragionamento né la formulazione matematica del problema.
Si possono aggiungere altre variabili dall’elevamento a potenza di quelle presenti o dalla loro moltiplicazione: i parametri sono detti <em>gradi di libertà</em> del modello.
Aggiungere troppi gradi di libertà però può provocare overfitting dei dati, oltre a ridurre l’interpretabilità del modello.</p>
<div id="critica" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Critica</h3>
<p>Il modello lineare, pur essendo molto semplice, si basa su delle assunzioni molto forti.</p>

<p>I residui devono avere media nulla e devono essere indipendenti (e quindi anche incorrelati) per tutti i valori di <span class="math inline">\(\underline{X}\)</span>.
Inoltre la varianza dei residui deve essere costante (devono cioè essere <em>omoschedastici</em>).
<span class="math display">\[\begin{equation*}
  \underline{\epsilon} = N(\underline{\mu}, \sigma{}I)
\end{equation*}\]</span></p>
<p>Per verificare queste ipotesi, non esiste un test considerato valido, tuttavia si usano strumenti grafici e test statistici, parametrici o non parametrici. 
Per verificare la distribuzione del vettore dei residui, si usano i test Kolmogorov-Smirnoff o Shapiro-Wilk, mentre Durbin-Watson è considerato valido per calcolare l’interdipendenza dei residui.
La distanza di Cook, inoltre, stabilisce se un’osservazione è particolarmente influente per la stima del modello. 
È possibile ridurre l’eteroschedasticità del modello operando sul logaritmo della variabile. </p>

<p>Un coefficiente può anche non essere particolarmente significativo nel modello (ha cioè peso pari a <span class="math inline">\(0\)</span>).
Bisogna dunque calcolare quali coefficienti sono significativamente non nulli; tuttavia, avendo a disposizione solamente la stima, sono necessari test statistici: basta calcolare un intervallo di confidenza ed escludere, con <span class="math inline">\(\alpha\)</span> pari a quello dell’intervallo, i coefficienti per cui il valore <span class="math inline">\(0\)</span> è interno all’intervallo.
Altro approccio è effettuare un test statistico (t-test) sulla significatività del singolo coefficiente ed escludere con <span class="math inline">\(\text{p-value} &gt; \alpha\)</span>.</p>
</div>
<div id="valutazione" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Valutazione</h3>
<p>Il coefficiente <span class="math inline">\(R^2\)</span> di determinazione rappresenta la percentuale di varianza totale spiegata dal modello:
<span class="math display">\[\begin{equation*}
  R^2 = 1 - \frac{RSS}{TSS} = 1 - \frac{\sum^n_{i=1}{(y_i - \hat{y}_i)^2}}{\sum^n_{i=1}{(y_i - \bar{y}_i)^2}}
\end{equation*}\]</span></p>
<p>Si può comunque verificare l’overfitting: si usa il coefficiente aggiustato.
<span class="math display">\[\begin{equation*}
  \tilde{R}^2 = 1 - (1 - R^2)\frac{m-1}{m-k-1}
\end{equation*}\]</span>
che generalmente assume valori minori di <span class="math inline">\(R^2\)</span>.
Se la differenza tra i due valori non è particolarmente alta, (probabilmente) non si verifica l’overfitting. </p>

<p>In un modello lineare semplice, si distinguono l’intervallo di confidenza, che contiene il valore medio <span class="math inline">\(E[\underline{y} | \underline{X}]\)</span>, e l’intervallo di previsione, che contiene la singola realizzazione <span class="math inline">\(y\)</span>.</p>

<p>Sono possibili una selezione <em>forward</em> e una selezione <em>backward</em>.
La prima parte dal modello vuoto e inserisce variabili a ogni passo del ciclo; si usa con un grande numero di variabili esplicative per semplificare il modello.
L’approccio backward invece parte dal modello pieno ed esclude variabili a ogni ciclo; si usa con poche variabili per eliminare quelle poco significative.</p>
</div>
</div>
</div>
<div id="class-imbalance-problem-feature-selection-and-non-binary-class" class="section level1">
<h1><span class="header-section-number">4</span> Class Imbalance Problem, Feature Selection and Non Binary Class</h1>
<div id="class-imbalance-problem" class="section level2">
<h2><span class="header-section-number">4.1</span> Class Imbalance Problem</h2>
<p>Si considera il caso in cui una variabile categoriale è particolarmente sbilanciata, con valori di un livello nettamente più alti rispetto ad un altro.
In una classificazione binaria, la classe rara è quella con poche osservazioni e classificata come la classe positiva (+1), mentre la rimanente classe maggioritaria viene classificata come negativa (-1).
Prendendo in considerazione la matrice di confusione, si considerano i seguenti rapporti:</p>
<ul>
<li>Il <em>TNR</em> (True Negative Rate), detta anche <em>Specificity</em>, è il rapporto tra le osservazioni negative predette correttamente dal modello di classificazione:
<span class="math display">\[TNR = \frac{TN}{TN + FP}\]</span></li>
<li>Il <em>TPR</em> (True Positive Rate), detta anche <em>Sensitivity</em>, è il rapporto tra le osservazioni positive predette correttamente dal modello di classificazione:
<span class="math display">\[TPR = \frac{TP}{TP + FN}\]</span></li>
<li>Il <em>FPR</em> (False Positive Rate) è il rapporto tra le osservazioni negative predette come la classe positiva del modello di classificazione:
<span class="math display">\[FPR = \frac{FP}{TN + FP}\]</span></li>
<li>Il <em>FNR</em> (False Negative Rate) è il rapporto tra le osservazioni positive predette come la classe negativa del modello di classificazione:
<span class="math display">\[FNR = \frac{FN}{TP + FN}\]</span></li>
</ul>
<p>La <em>precision</em> e <em>recall</em> sono due metriche di misura per determinare quale delle due classi è considerata più importante rispetto all’altra.
La <strong>Precision</strong> è definita come il rapporto tra le osservazioni positive correttamente predette e il gruppo che il modello ha classificato come positivo:</p>
<p><span class="math display">\[p = \frac{TP}{TP + FP}\]</span></p>
<p>Più è alta la precision, meno sarà il numero di FP e quindi errori commessi dal modello.
La <strong>Recall</strong>, invece, misura il rapporto tra le osservazioni positive correttamente predette:
<span class="math display">\[r = \frac{TP}{TP + FN}\]</span></p>
<p>Un’alta recall implica poche osservazioni positive classificate come classe negativa.
Essa è equivalente al calcolo del TPR.
Tipicamente, precision e recall sono combinati tra loro formando la metrica chiamata <span class="math inline">\(F_1\)</span>, calcolata come media armonica tra le due metriche:</p>
<p><span class="math display">\[F_1 = \frac{2rp}{r + p}\]</span></p>
<p>Un alto valore di <span class="math inline">\(F_1\)</span> implica elevati valori sia della precision che della recall.
Questa metrica è generalizzabile calcolando una nuova metrica, <span class="math inline">\(F_{\beta}\)</span> per esaminare la rilevanza tra le misure:</p>
<p><span class="math display">\[F_{\beta} = \frac{(\beta^2 + 1) rp}{r + \beta^2 p} \in [0, \infty)\]</span></p>
<p>Osservazioni:</p>
<ul>
<li><span class="math inline">\(F_{\beta}\)</span> con <span class="math inline">\(\beta = 0\)</span> è la precision;</li>
<li><span class="math inline">\(F_{\beta}\)</span> con <span class="math inline">\(\beta = \infty\)</span> è la recall.</li>
</ul>
</div>
<div id="counting-the-cost" class="section level2">
<h2><span class="header-section-number">4.2</span> Counting the Cost</h2>
<p>Dopo aver diviso il dataset in Training e Test e dopo aver evidenziato il miglior modello, si confronta la matrice di confusione rispetto al matrice di confusione del modello standard.
Bisogna anche controllare il <strong>costo</strong> del processo del modello, ricercato sempre dalle aziende.
Il costo è calcolato nel seguente modo:</p>
<p><span class="math display">\[Cost = C_{_{--}}TN + C_{_{-+}}FP + C_{_{+-}}FN + C_{_{++}}TP\]</span></p>
<p>Se i costi sono simmetrici, è possibile concludere che i costi sono proporzionali alla accuracy.
In questo caso, la numerosità sarà <span class="math inline">\(N = TP + TN + FP + FN\)</span>, l’accuracy <span class="math inline">\(acc = \frac{TP + TN}{N}\)</span> e il costo sarà:</p>
<p><span class="math display">\[\begin{align}
  Cost &amp;= p(TP + TN) + q(FN + FP) =     \\
       &amp;= p(TP + TN) + q(N - TP - TN) = \\
       &amp;= qN - (q - p) (TP + TN) =      \\
       &amp;= N[q - (q - p)(TP + TN)]
\end{align}\]</span></p>
<div id="cumulative-gains" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Cumulative Gains</h3>
<p>Dato un modello di classificazione che abbia come output la probabilità prevista per la classe positiva, bisogna trovare un sottoinsieme nella quale le osservazioni hanno alta proporzione delle osservazioni positive ed avere un valore più alto del dataset iniziale.
Si applica il modello ad un numero definito di osservazioni e si calcolano le probabilità, ordinandole in modo decrescente.
Si sceglie un sottoinsieme con la massima proporzione possibile.
Si costruiscono le <strong><em>Lift</em></strong>, osservando quanto sbaglia il modello.
Le Lift sono calcolate come rapporto tra la percentuale di record positivi (+1) su quelli negativi (-1) e il numero di osservazioni del campione in percentuale sul dataset originale.
Le lift possono essere anche rappresentate in termini grafici e permette di scegliere il miglior campione che massimizza la percentuale di record positivi.</p>
</div>
<div id="lift-chart" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Lift Chart</h3>
<p>Le Cumulative Gains possono essere rappresentate anche con le Lift Chart, che presenta sulle ascisse la percentuale del campione sul dataset originale e sulle ordinate il valore delle Lift.
Perciò, data una percentuale del campione, è possibile osservare il valore dei record classificati positivamente.</p>
</div>
<div id="roc-curve" class="section level3">
<h3><span class="header-section-number">4.2.3</span> ROC Curve</h3>
<p>Le Lift Chart sono sempre messe in relazione con una tecnica grafica per valutare i modelli di classificazione, chiamata <strong>R</strong>eceiver <strong>O</strong>perating <strong>C</strong>haracteristic (ROC).
Essa rappresenta la percentuale di Falsi Positivi sull’asse delle ascisse e la percentuale di Veri Positivi sull’asse delle ordinate.
Questo grafico illustra le performance dei modelli di classificazione senza considerare la distribuzione della classe o errori di costo.
Molte volte capita che la rappresentazione grafica della ROC sia seghettata: questo dipende dalla numerosità dei dati.
Non sempre è possibile osservare il miglior modello in termini di classificazione, poiché spesso un modello classifica meglio una parte dei dati rispetto ad un’altra.</p>
</div>
</div>
<div id="feature-selection" class="section level2">
<h2><span class="header-section-number">4.3</span> Feature Selection</h2>
<p>La Feature Selection è una operazione che permette di scegliere il numero di variabili esplicative del modello per osservare quali di queste sono <em>ridondanti</em>, contenenti informazioni già presenti in altre covariate, oppure <em>irrilevanti</em>, non contenendo alcuna informazione significativa per la variabile risposta.
Sono possibili diversi approcci:</p>
<ul>
<li><em>Forza bruta</em>: si applicano tutti i possibili campionamenti di variabili disponibili come variabili di input nel modello di classificazione. Per calcolare il numero possibile di campioni, si calcola una combinazione:</li>
</ul>
<p><span class="math display">\[\sum_{n = 1}^k{k \choose n}\]</span></p>
<p>All’aumentare del numero di variabili esplicative aumentano esponenzialmente i possibili campioni;</p>
<ul>
<li><em>Embedded</em>: si selezionano le covariate in base alla modalità di apprendimento di alcuni classificatori, come Bayesian Network, Alberi Decisionali, ecc;</li>
<li><em>Filter</em>: la selezione avviene prima di ogni apprendimento di un modello. La scelta delle coviariate avviene dato un campione di attributi alla funzione obiettivo, che darà un riscontro, in inglese <em>feedback</em>. Il processo termina all’ottenimento del campione di covariate ottimali che verrà utilizzato successivamente per il modello di classificazione;</li>
<li><em>Wrapper</em>: il classificatore è utilizzato per cercare il miglior campione di covariate possibili. La scelta delle covariate avviene tramite un campione di esse al classificatore che darà un feedback. Il processo termina all’ottenimento del campione ottimale che verrà utilizzato per il modello di classificazione.</li>
</ul>
<p>La differenza principale tra la selezione Filter e Wrapper è che il primo seleziona le covariate in base ad una funzione obiettivo, mentre la seconda direttamente dal modello di classificazione.
La modalità di selezione con l’approccio Filter può essere di tipo:</p>
<ul>
<li><em>Univariato</em>: si sceglie una misura di associazione tra l’attributo possibile ordinata in base alla misura di associazione e la risposta e si selezionano i migliori attributi per il modello di classificazione. Vengono eliminati le covariate non significative, ma non quelle ridondanti (t-test, ANOVA, permutazione);</li>
<li><em>Multivariato</em>: si identificano solamente le covariate strettamente correlate alla risposta, eliminando le variabili ridondanti e non significative, con l’operazione chiamata <em>Correlation Feature Selection</em>.</li>
</ul>
<p>I principali vantaggi di utilizzare la feature selection è la riduzione dei costi nella collezione dei dati ottenendo modelli di classificazione con alta Accuracy e alta interpretabilità, ma soprattutto riducendo l’overfitting del modello.</p>
</div>
<div id="train-validation-test-and-feature-selection" class="section level2">
<h2><span class="header-section-number">4.4</span> Train, Validation, Test and Feature Selection</h2>
<p>Alcuni modelli statistici permettono di avere parametri, come la regolarizzazione nelle Neural Network.
Si presenta quindi un problema di ottimizzazione globale per cui non è possibile risolvere la seguente equazione:</p>
<p><span class="math display">\[E(w, \lambda) = \frac{1}{m} \sum^m_{i = 1}(y_i - y_i)^2 + \frac{\lambda}{2} \sum^K_{j = 1} w_i^2\]</span></p>
<p>con <span class="math inline">\(\lambda\)</span> parametro di iper-regolarizzazione (o di penalizzazione) e <span class="math inline">\(K\)</span> il numero di parametri liberi delle NN.</p>
<p><strong>Non</strong> utilizzare il dataset di Training per regolarizzare il parametro <span class="math inline">\(\lambda\)</span>, perché si potrebbe ottenere overfitting; invece, si divide ulteriormente il Train in una parte in Validation (1/3 del Training).
In questo modo, si regolarizza il parametro per ottenere nel Test una stima imparziale della misura di performance.</p>
<p>Utilizzando il metodo Filter è consigliato dividere il dataset di partenza in Train e Test, in quanto la rilevanza e la ridondanza delle variabili sono stimate tramite il Train, per poi applicare l’apprendimento del classificatore.
Infine, si stimano le performance applicando il classificatore al Test.</p>
<p>Utilizzando il metodo Wrapper è consigliato dividere il dataset in Train + Validation e Test.
Il Validation è utilizzato per ottimizzare le performance quando diverse covariate vengono utilizzate dal modello di classificazione.
Il Train + Validation è utilizzato per l’apprendimento del classificatore.
Infine, si stimano le performance applicando il classificatore al Test.</p>
</div>
<div id="non-binary-classification" class="section level2">
<h2><span class="header-section-number">4.5</span> Non Binary Classification</h2>
<p>Una classificazione non binaria è una classificazione nella quale una variabile categoriale ha più di due livelli.
Esistono due tipi di classificazioni non binarie:</p>
<ul>
<li>Classificazione <em>Multi-Class</em> (classi ordinate);</li>
<li>Classificazione <em>Multi-Label</em> (Ranking problem nella quale si considera l’ordinamento dei livelli).</li>
</ul>
<p>Il problema di classificazione non binaria è tipicamente risolta utilizzando la trasformazione <em>Uno vs Tutti</em> nella quale per ogni livello si identifica una opzione in modo da ottenere un set di classificatori binari.
Si sviluppa una tipologia di classificazione per ogni valore della classe (<em>è della classe o no?</em>).
Per ognuna delle classi si calcola il relativo modello di classificazione.
Il valore con la probabilità più alta la si classifica alla corrispondente classe.
Nel caso di multi-label, si sceglie una soglia per la quale si accetta la categorizzazione della classe; è possibile che si verifichino i seguenti problemi:</p>
<ul>
<li>Nessuna soglia superata, quindi soggetto non etichettato;</li>
<li>Più di un livello supera la soglia, quindi più etichette.</li>
</ul>
</div>
</div>
<div id="clustering" class="section level1">
<h1><span class="header-section-number">5</span> Clustering</h1>
<p>La Cluster Analysis è una particolare analisi che ha lo scopo di raggruppare soggetti basati sulle descrizioni e sulle loro relazioni.
In particolare, si basa su due concetti fondamentali:</p>
<ul>
<li>Le istanze all’interno di un cluster possono essere <strong>simili</strong>, quindi relazionati ad un altro (o viceversa);</li>
<li>Se due istanze sono simili, allora sono <strong>omogenee</strong>, altrimenti <strong>eterogenee</strong>.</li>
</ul>
<p>La cluster analysis è applicata a due finalità:</p>
<ul>
<li><em>Understanding</em>, nella quale si classificano gruppi di oggetti che hanno delle caratteristiche comuni, con ambiti di applicazione in biologia, business, ecc.;</li>
<li><em>Utility</em>, nella quale si riassumono le principali caratteristiche di un cluster. L’obiettivo è quello di identificare il cluster prototipo più rappresentativo.</li>
</ul>
<p>Bisogna tenere in considerazione che la definizione di cluster è imprecisa e la miglior definizione dipende dalla natura del dato e dal risultato finale che si vuole ottenere.</p>
<div id="tipologie-di-cluster" class="section level2">
<h2><span class="header-section-number">5.1</span> Tipologie di Cluster</h2>
<p>Esistono molte tecniche di clustering:</p>
<ul>
<li>Partizionale <em>vs</em> Gerarchico;</li>
<li>Esclusivo <em>vs</em> Overlapping <em>vs</em> Fuzzy;</li>
<li>Completo <em>vs</em> Parziale.</li>
</ul>
<p>Il metodo di clustering <strong><em>Partizionale</em></strong> è una divisione dei dati in modo da ottenere dei cluster senza che ci sia una altro cluster superiore.
Il metodo <strong><em>Gerarchico</em></strong>, invece, permette di avere dei sub-cluster in un cluster organizzati come un albero, <em>ma</em> diverso da un dendrogramma.</p>
<p>Il metodo di clustering <strong><em>Esclusivo</em></strong> è una particolare tecnica nella quale tutti i cluster sono esclusivi, ovvero ogni osservazione è assegnata ad un singolo cluster.
Il metodo <strong><em>Overlapping</em></strong>, invece, permette il contrario: le osservazioni possono essere divisi in più cluster.
Infine, il metodo <strong><em>Fuzzy</em></strong> permette ad un singolo dato di appartenere ad ogni cluster con un peso di appartenenza specifico che varia da 0 ad 1.</p>
<p>Il metodo di clustering <strong><em>Completo</em></strong> permette di assegnare ad ogni osservazione presente nel dataset ad un cluster.
Il metodo <strong><em>Parziale</em></strong>, invece, non necessita di assegnare ogni osservazione ad un cluster: alcune osservazioni possono non appartenere ad un gruppo ben definito.</p>
<p>Bisogna tenere in considerazione che esistono diverse concezioni di prove di clustering:</p>
<ul>
<li><em>Cluster ben separati</em>, nella quale ogni oggetto nei cluster è omogeneo al loro interno ed eterogeneo all’esterno. Questa è la definizione ideale di cluster; in realtà, sarà molto difficile dividere eccellentemente due cluster;</li>
<li><em>Cluster Prototype-Based</em>, nella quale ogni oggetto è simile ai prototipi che definiscono i cluster. Molte volte questo prototipo è il centroide. Se non è rappresentativo, si utilizza;</li>
<li><em>Cluster Density-Based</em>, nella quale un cluster è una regione densa di oggetti circondata da un altro cluster di bassa densità;</li>
<li><em>Cluster Graph-Based</em>, nella quale i dati sono rappresentati tramite un grafo. Un cluster è definito come una componente connessa costituita da nodi ed archi, perciò un cluster è definito come un insieme di componenti connesse.</li>
</ul>
<p>Da un dataset, si compie feature selection, nella quale si selezionano le variabili più significative, o feature extraction.
Successivamente si seleziona l’algoritmo che misura la prossimità tra i cluster e si costruisce un criterio di selezione. Dopo l’apprendimento, si validano le divisioni dei cluster, prendendo in considerazioni gli obiettivi dello studio.
Infine, si traggono le conclusioni per migliorare la conoscenza dei dati per studi statistici successivi.</p>
</div>
<div id="prossimità" class="section level2">
<h2><span class="header-section-number">5.2</span> Prossimità</h2>
<p>La Cluster Analysis prende in considerazione i concetti di similarità e dissimilarità tra le osservazioni:</p>
<ul>
<li>La <strong><em>similarità</em></strong> (<span class="math inline">\(s\)</span>) tra due record è una misura numerica del grado per cui sono simili. Valori elevati tra similarità implica la somiglianza tra i due oggetti: <span class="math inline">\(s \in [0, 1]\)</span>;</li>
<li>La <strong><em>dissimilarità</em></strong> (<span class="math inline">\(d\)</span>) tra due oggetti è una misura numerica del grado per cui sono differenti. Di solito <span class="math inline">\(d \in [0, 1]\)</span>, ma possono anche assumere valori <span class="math inline">\(\in [0, \infty )\)</span>.</li>
</ul>
<p>Spesso si applicano delle trasformazioni lineari per converitre una similarità ad una dissimilarità (o viceversa) comprese tra i valori 0 ed 1:</p>
<p><span class="math display">\[\begin{aligned}
    s&#39; &amp;= \frac{s - min_s}{max_s - min_s}
    d&#39; &amp;= \frac{d - min_d}{max_d - min_d}
  \end{aligned}\]</span></p>
<p>Se la prossimità ha valori compresi tra 0 ed infinito, si compie una trasformazione non lineare, ma i valori della trasformazione non hanno la stessa relazione con l’altra in una nuova scala, perché distorti:</p>
<p><span class="math display">\[d&#39; = \frac{d}{1 + d}\]</span></p>
<p>Alti valori della dissimilarità originale sono compressi intorno ad 1 usando la nuova trasformazione.
Si può passare dalla similarità alla dissimilarità (o viceversa) con il complementare: <span class="math inline">\(d = 1-s\)</span> e <span class="math inline">\(s = 1-d\)</span>.
Un altro approccio utile è definire la similarità come il negativo della dissimilarità (o viceversa):<span class="math inline">\(s = -d\)</span></p>
<p>La prossimità tra due record è una funzione della prossimità tra gli attributi corrispondenti dei due record.
Si descrive la prossimità tra due record avendo un singolo attributo:</p>
<ul>
<li><em>Nominali</em>: <span class="math inline">\(s = 1\)</span> se <span class="math inline">\(x = y\)</span>, dove <span class="math inline">\(x\)</span> ed <span class="math inline">\(y\)</span> sono due record, altrimenti 0 (sia binari che categoriali);</li>
</ul>
<p><span class="math display">\[d =
\begin{cases}
  0 &amp; \quad
  \text{se }x = y\\ 
  1 &amp; \quad
  \text{altrimenti}
\end{cases}\]</span></p>
<ul>
<li><em>Ordinali</em>: <span class="math inline">\(d = \frac{|x - y|}{n - 1}\)</span>, dove n è il numero di variabili ordinali, quindi <span class="math inline">\(s = 1-d\)</span>. In questo caso si stanno assumendo intervalli equi tra i livelli, considerando una scala lineare;</li>
<li><em>Numerici</em>: si considera la dissimilarità e similarità introdotte ad inizio capitolo: <span class="math inline">\(d = |x-y|\)</span>.</li>
</ul>
<div id="misure-di-prossimità" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Misure di Prossimità</h3>
<p>Esistono diversi modi per calcolare la prossimità tra due record.</p>
<p>Le distanze sono considerate come dissimilarità con certe caratteristiche.
Le distanze più importanti appartengono alla famiglia chiamata <strong><em>Distanza di Minkowski</em></strong>:
<span class="math display">\[d(x, y) = \sqrt[r]{\sum^n_{k = 1}|x_k - y_k|^r}\]</span></p>
<ul>
<li>se <span class="math inline">\(r = 1\)</span>, allora si ottiene la distanza di Manhattan;</li>
<li>se <span class="math inline">\(r = 2\)</span>, allora si ottiene la distanza Euclidea;</li>
<li>se <span class="math inline">\(r = \infty\)</span>, allora si ottiene la distanza Suprema.</li>
</ul>
<p>Le distanze di Minkowski presentano le seguenti proprietà:</p>
<ul>
<li>Non Negatività: <span class="math inline">\(d(x,y) \geq 0\)</span>, <span class="math inline">\(d(x, y) = 0\)</span> se <span class="math inline">\(x = y\)</span>;</li>
<li>Simmetria: <span class="math inline">\(d(x, y) = d(y, x)\)</span>;</li>
<li>Diseguaglianza Triangolare: <span class="math inline">\(d(x, z) \leq d(x, y) + d(y, z)\)</span>.</li>
</ul>
<p>La similarità soddisfa le prime due proprietà, ma non la terza.</p>
<p>Si presentano altre misure di prossimità.
Esistono diversi motivi per cui un coefficiente è migliore di un altro in diversi contesti: il <strong><em>S</em></strong>imple <strong><em>M</em></strong>atching <strong><em>C</em></strong>oefficient (SMC) viene utilizzato quando tutti gli attributi binari sono simmetrici, ovvero tutti i valori 0 ed 1 sono equamente distribuiti.</p>
<p><span class="math display">\[SMC(x, y) = \frac{\#attributi\ veri}{\#attributi} \in [0,1]\]</span></p>
<p>Il <strong><em>Coefficiente di Jaccard</em></strong> si usa quando gli attributi non sono simmetrici (solo attributi binari).</p>
<p><span class="math display">\[J(x,y)=\frac{\#presenza congiunte}{\#attributi tranne 00}=\frac{f_{11}}{f_{11}+f_{10}+f_{01}}\]</span></p>
<p>Esiste anche una versione estesa, chiamata Extended Jaccard Coefficient, utilizzata spesso per l’analisi di documenti:</p>
<p><span class="math display">\[EJ(x,y)=\frac{x \times y}{||x^2||+||y^2||-x\times y}\]</span></p>
<p>La <strong><em>Similarità del Coseno</em></strong> è una misura molto simile al Coefficiente di Jaccard, ma è possibile anche introdurre attributi non binari.
Questa misura è estremamente utile per comparare poche osservazioni, utilizzata nella Information Retrieval dove i documenti sono rappresentati come vettori;</p>
<p><span class="math display">\[cos(x,y)=\frac{x\times y}{||x|| \times ||y||}\in [0,1]\]</span></p>
<p>La <strong><em>Correlazione</em></strong> (non ho nulla da aggiungere, so tutto):</p>
<p><span class="math display">\[corr(x,y)=\frac{cov(x,y)}{\sigma_{x} \sigma_{y}} \in [-1,+1]\]</span></p>
</div>
</div>
</div>
<div id="clustering-evaluation" class="section level1">
<h1><span class="header-section-number">6</span> Clustering Evaluation</h1>
<p>Esistono molti algoritmi con diversi parametri per compiere analisi di clustering, ma la valutazione dei cluster non è una operazione ben sviluppata perchè poco utilizzata nella Cluster Analysis, anche se molto importante.</p>
<p>Un algoritmo di clustering ha l’obiettivo di trovare dei cluster all’interno dei dati anche se non esistono delle divisioni naturali.
Per valutare i risultati dell’algoritmo bisogna determinare la tendenza di costruzione di cluster del dataset ed il corretto numero di cluster (anche se non esiste un vero e proprio numero).
Per risolvere questi problemi si utilizzano delle misure di valutazione, anche chiamati <em>Indici</em>, che possono essere di tre tipi.</p>
<div id="misure-di-valutazione" class="section level2">
<h2><span class="header-section-number">6.1</span> Misure di Valutazione</h2>
<div id="external-measure" class="section level3">
<h3><span class="header-section-number">6.1.1</span> External Measure</h3>
<p>L’indice Esterno, chiamato in inglese <strong><em>External Measure</em></strong>, misura se l’estensione della struttura dei cluster corrisponde a qualche struttura esterna.
Si prendono in considerazione una partizione <span class="math inline">\(P={P_1, ..., P_R}\)</span> di un datasaet di <span class="math inline">\(m\)</span> righe divise in <span class="math inline">\(R\)</span> categorie, e una partizione <span class="math inline">\(C = {C_1, ..., C_K}\)</span> ottenuto da un algoritmo di clustering che partiziona i dati in <span class="math inline">\(K\)</span> cluster.
L’indice supervisionato compara le partizioni <span class="math inline">\(P\)</span> e <span class="math inline">\(C\)</span> considerando 4 casi:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> appartengono alla stesso cluster di <span class="math inline">\(C\)</span> e alla stessa categoria di <span class="math inline">\(P\)</span>;</li>
<li><span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> appartengono alla stesso cluster di <span class="math inline">\(C\)</span>, ma ad un diversa categoria di <span class="math inline">\(P\)</span>;</li>
<li><span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> appartengono ad un cluster diverso di <span class="math inline">\(C\)</span>, ma alla stessa categoria di <span class="math inline">\(P\)</span>;</li>
<li><span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> appartengono ad un cluster diverso di <span class="math inline">\(C\)</span> e ad una categoria diversa di <span class="math inline">\(P\)</span>;</li>
</ol>
<p>Il numero totale di coppie è pari a <span class="math inline">\(M=\frac{m(m-1)}{2}=a+b+c+d\)</span>. Si prendono in considerazione diversi indici:</p>
<ul>
<li>Rand: <span class="math inline">\(R = \frac{a + d}{M} \in [0, 1]\)</span></li>
<li>Jaccard: <span class="math inline">\(J = \frac{a}{a + b + c} \in [0, 1]\)</span></li>
<li>Fowleks and Mallows: <span class="math inline">\(FM = \sqrt{\frac{a}{a + b} \times \frac{a}{a + c}} \in [0, 1]\)</span></li>
<li><span class="math inline">\(\Gamma\)</span> Statistics: <span class="math inline">\(\Gamma = \frac{Ma - (a + b)(a + c)}{\sqrt{(a + b)(a + c)(M-a-b)(M - a - c)}} \in [-1, +1]\)</span></li>
</ul>
<p>Più i valori di questi indici si avvicinano ad 1, più le partizioni <span class="math inline">\(C\)</span> e <span class="math inline">\(P\)</span> saranno simili.</p>
</div>
<div id="internal-measure" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Internal Measure</h3>
<p>L’indice Interno, chiamato in inglese <strong><em>Internal Measure</em></strong>, misura la bontà della struttura dei cluster rispetto alle informazioni esterne.
Questi indici tengono in considerazione anche di misure di <em>coesione</em>, che determina quanto sono relazionate i record all’interno dei cluster, e <em>separazione</em>, che determina quanto sono distinti, perciò ben separati, i cluster.
In generale, si considera l’insieme dei <span class="math inline">\(K\)</span> cluster <span class="math inline">\(C = {C_1, ..., C_K}\)</span>.
La validità generale dei cluster è calcolata come una somma pesata dei singoli cluster:</p>
<p><span class="math display">\[overall_validity = \sum_{i = 1}^{K} w_i \times validity(C_i)\]</span></p>
<p>con la funzione di validità considerata come coesione (<span class="math inline">\(c\)</span>), separazione (<span class="math inline">\(s\)</span>) od una combinazione delle due.
Il valore dei pesi dipende dalla misura di valutazione dei cluster.
Considerando come funzione di validità la coesione, valori alti implicano un’alta coesione, mentre per la separazione valori più bassi.</p>
<p>Per i cluster <em>Graph-Based</em>, la coesione di un di un cluster è definito come somma dei pesi che collegano i punti all’interno di un cluster:</p>
<p><span class="math display">\[c(C_i) = \sum_{x,y \in C_i}p(x, y) = \sum_{x, y \in C_i} s(x, y)\]</span></p>
<p>La coesione e la similarità sono massimizzate quando la dissimilarità è minimizzata.</p>
<p>La separazione tra due cluster può essere misurata come la somma dei pesi che collegano i punti di un cluster ad un altro:</p>
<p><span class="math display">\[s(C_i, C_j) = \sum_{x \in C_i, y \in C_j} p(x, y) = \sum_{x \in C_i, y \in C_j} s(x,y)\]</span></p>
<p>La separazione e la similarità sono minimizzate quando la dissimilarità è massimizzata.</p>
<p>Per i cluster <em>Proototype-Based</em>, la coesione di un clsuetr è definito come la somma delle prossimità rispetto al centroide (o medoide) del cluster:</p>
<p><span class="math display">\[c(C_i) = \sum_{x \in C_i} p(x, c_i) = \sum_{x \in C_i}s(x, c_i)\]</span></p>
<p>La separazione tra due cluster è definita come la prossimità tra i centroidi (o medoidi) dei due cluster:</p>
<p><span class="math display">\[s(C_i, C_j) = p(c_i, c_j) = (c_i, c_j)s\]</span></p>
<p>Un’altra modalità di calcolo della misura è possibile utilizzando il centroide complessivo (in questo caso <span class="math inline">\(c\)</span>):</p>
<p><span class="math display">\[s(C_i) = p(c_i, c) = s(c_i, c)\]</span></p>
<p>Si possono utilizzare diversi pesi per il calcolo della validità di un cluster, in base anche alla grandezza di un cluster.
Per esempio, se si utilizza la coesione nei Graph-Based il peso da utilizzare è <span class="math inline">\(1/m_i\)</span>, mentre per i Prototype-Based si utilizza il peso <span class="math inline">\(1\)</span>.</p>
<p>Per migliorare la qualità dei cluster, si possono clusterizzare i record rispetto a uno specifico valore della validità del cluster, tramite la coesione o la separazione.
È possibile valutare la validità dei punti all’interno di un cluster: i record più interni contribuiscono di più alla coesione e separazione dei cluster rispetto a quelli esterni.
Per questa valutazione si considera la <em>Silhouette Coefficient</em>, combinando le misure di separazione e coesione per l’i-esima riga:</p>
<p><span class="math display">\[s_i = \frac{b_i - a_i}{max(b_i, a_i)} \in [-1, +1]\]</span></p>
<ul>
<li><span class="math inline">\(a_i\)</span> indica la distanza medie rispetto alle altre righe all’interno del cluster;</li>
<li><span class="math inline">\(b_i\)</span> indica la minima distanza degli altri cluster.</li>
</ul>
<p>Un valore negativo implica una distanza media dei punti nel cluster (<span class="math inline">\(a_i\)</span>) maggiore della minima distanza media dei punti degli altri cluster (<span class="math inline">\(b_i\)</span>).
Una misura di validità di clusterizzazione è l’ <strong><em>Average Silhouette Coefficient</em></strong>, definita come la media dei singoli coefficienti dei punti appartenti al cluster.</p>
<p>Un’altra metrica, utilizzata soprattuto nei clustering gerarchici, è la <strong><em>Cophenetic Corelation Coefficient</em></strong>, che misura il grado di similarità tra la matrice di prossimità <span class="math inline">\(P\)</span> e la matrice Cophenetica <span class="math inline">\(Q\)</span>, definita nell’intervallo <span class="math inline">\([-1, +1]\)</span>, dove 1 indica la similarità tra le due matrici ed un buon fit di gerarchizzazione dei dati.</p>
</div>
<div id="relative-measure" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Relative Measure</h3>
<p>L’indice relativo, chiamato in inglese <strong><em>Relative Measure</em></strong>, compara diversi cluster in termini supervisionati o non supervisionati.
Gli indici interni ed esterni richiedono test statistici che possono portare ad un alto peso computazionale.
Essa elimina questo requisito e si concentra sul confronto dei risultati della clusterizzazione, utilizzando diversi algoritmi o lo stesso con diversi parametri di input.</p>
<p>In questo caso si introduce il <em>Problema fondamentale</em> della validità di un cluster: <strong>determinare il numero ideale di cluster</strong>.
Per risolvere questo problema si possono proiettare i dati in 2/3 dimensioni Euclidee utilizzando tecniche di visualizzazione che possono fornire il numero ideale.
Questo metodo è utilizzato solo per piccoli scopi di applicazione. Esistono altri indici per risolvere il problema:</p>
<ul>
<li>Calinski e Harabasz, per la quale il massimo valore di <span class="math inline">\(K\)</span> corrispondente è preso dal numero ottimale di cluster;</li>
<li>Dunn, per la quale il massimo valore di <span class="math inline">\(K\)</span> corrispondente è preso dal numero ottimale di cluster. Un alto valore indica cluster compatti e ben separati;</li>
<li>Davies-Bouldin, per la quale il minimo valore di <span class="math inline">\(K\)</span> corrispondente è preso dal numero ottimale di cluster.</li>
</ul>
<p>Per modelli di mistura di probabilità si presentano i principali indici:</p>
<ul>
<li><strong><em>A</em></strong>kaike <strong><em>I</em></strong>nformation <strong><em>C</em></strong>riterion (AIC), per la quale il minimo valore di K corrispondente è preso dal numero ottimale di cluster;</li>
<li><strong><em>M</em></strong>inimum <strong><em>D</em></strong>escription <strong><em>L</em></strong>ength (MDL), per la quale il minimo valore di K corrispondente è preso dal numero ottimale di cluster;</li>
<li><strong><em>B</em></strong>ayesian <strong><em>I</em></strong>nformation <strong><em>C</em></strong>riterion (BIC), per la quale il minimo valore di K corrispondente è preso dal numero ottimale di cluster.</li>
</ul>
<p>Per un algoritmo di clusterizzazione che richiede il numero dei <span class="math inline">\(K\)</span> cluster dall’utente, il numero ottimale di cluster è ottenuto compiendo un algoritmo <span class="math inline">\(r\)</span> volte dove <span class="math inline">\(K\)</span> è compreso tra un valore minimo e massimo scelto dall’utente.
Inanzitutto bisogna scegliere l’algoritmo di clusterizzazione ed un indice di validità; successivamente si compie un ciclo nella quale il valore <span class="math inline">\(K = K_{min}\)</span> e si fa andare l’algoritmo di clustering, si calcola il valore dell’indice e <span class="math inline">\(q(i) = 1\)</span>.
Dopo aver concluso i due cicli si sceglie il valore migliore di <span class="math inline">\(\vec{q}\*\)</span> tra i valori proposti e lo si setta pari a <span class="math inline">\(Q(k) = \vec{q}\*\)</span>. Nel caso di strutture gerarchiche, gli indici di definiscono come <em>stopping rule</em>, che affermano il livello ottimale per il taglio del dendrogramma.</p>
</div>
</div>
<div id="validity-paradigm" class="section level2">
<h2><span class="header-section-number">6.2</span> Validity Paradigm</h2>
<p>Sia le misure interne che esterne sono strettamente correlate con metodi statistici e test d’ipotesi.
Il paradigma di validità dei cluster si basa sulla seguente ipotesi nulla: “Non esiste alcuna struttura nel dataset”.</p>
<p>Il paradigma procede nelle seguenti fasi:</p>
<ol style="list-style-type: decimal">
<li>Si identifica la struttura dei dati tramite un algoritmo di clusterizzazione ed il tipo di valutazione, interna od esterna;</li>
<li>Si determina l’indice di validità da utilizzare;</li>
<li>Si definisce l’ipotesi nulla della struttura nulla. Si possono utilizzare tre tipi di ipotesi: la <em>Random Position Hypotesis</em>, in cui tutte le posizioni dei dati di una specifica regione dello spazio sono equamente probabili (usata per dati numerici); la <em>Random Graph Hypotesis</em>, nella quale il ranghi delle matrici di prossimità sono equamente probabili (usata per prossimità ordinali ); la <em>Random Label Hypotesis</em>, nella quale le etichette dei dati sono equamente probabili (usata per tutti i tipi di dati);</li>
<li>Si stabilisce la distribuzione di fondo sotto la condizione d’ipotesi nulla, utilizzando metodi computazionali quali l’analisi di Montecarlo e il Bootstrapping;</li>
<li>Si calcola l’indice associato alla soluzione di clustering utilizzata;</li>
<li>Si testa l’ipotesi della struttura nulla comparando il valore dell’indice precedente sulla distribuzione di fondo dell’ipotesi nulla con un livello di confidenza pari ad <span class="math inline">\(\alpha\)</span>.</li>
</ol>
</div>
</div>
<div id="association-analysis" class="section level1">
<h1><span class="header-section-number">7</span> Association Analysis</h1>
<p>L’analisi delle associazioni analizza le transazioni effettuate, ovvero insiemi di elementi di lunghezza variabile che corrispondono ad operazioni unitarie effettuate dai clienti.
Un esempio è la lista della spesa degli utenti di un supermercato.
L’obiettivo è trovare rapporti di conseguenza, <em>antecedenti</em> e <em>conseguenti</em> che offrono dei vantaggi di strategia.
I dati sono rappresentati come variabili <em>booleane</em> nella quale ogni riga rappresenta una transazione e le collone ogni <em>item</em> (in questo caso i prodotti acquistati) nella transazione.</p>
<p>Sia <span class="math inline">\(I = {i_1, i_2, ..., i_k}\)</span> l’insieme degli item e con <span class="math inline">\(T = {t_1, t_2, ..., t_k}\)</span> l’insieme delle transazioni.
Un <strong><em>itemset</em></strong> è un insieme di item; se contiente <span class="math inline">\(k\)</span> item differenti, si chiama <em>k-itemset</em>.
Una transazione contiene più itemset di dimensioni diverse, avendo la possibilità di eleminare o aggiungere elementi.
La larghezza della transazione rappresenta il numero di item della transazione.</p>
<p>Il <em>support count</em> <span class="math inline">\(\sigma(X) = |\{t_i : X \subseteq t_i, t_i \in T\}|\)</span> conta il numero di k-itemset per determinare regole di associazione <span class="math inline">\(A \rightarrow B\)</span>, a patto che <span class="math inline">\(A \cap B = \varnothing\)</span>.
Si definisce <em>confidenza</em> il numero di volte in cui l’assocazione si ripete rispetto al numero di volte in cui appare l’antecedente, in percentuale:</p>
<p><span class="math display">\[c(A \rightarrow B) = \frac{\sigma(A \cup B)}{\sigma(A)}\]</span></p>
<p>Invece, il <em>supporto</em> è definito come il numero in cui una regola è applicata all’intero dataset, in percentuale:</p>
<p><span class="math display">\[s(A \rightarrow B) = \frac{\sigma(A \cup B)}{N}\]</span></p>
<p>L’idea è trovare regole con un grande support, poichè facili da trovare, ed alta confidenza, perchè attendibili.</p>
<p>Il supporto elimina anche regole che occorrono per puro caso, o regole poco applicabili e perciò non interessanti nel mondo reale, riducendo quindi il numero di regole considerate. Per trovare il numero ideae è sconsigliato il metodo a <em>forza bruta</em>, in quanto l’elevato numero di regole segue una legge esponenziale, quindi ad alto peso computazionale.
Il problema si risolve eliminando tutte le regole che si è sicuri non soddisfano una soglia minima di frequenza, poichè poco presenti nell’itemset e considerare le regole solo per gli elementi rimanenti.</p>
<div id="valutazione-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Valutazione</h2>
<p>La formazione di regole non deve essere troppo semplice e deve interessare gli esperti di dominio.
Esistono misure oggettive, indipendenti dal dominio, per calcolare la qualità delle regole formulate: si costruisce una matrice di confusione (come quella per i modelli di classificazione).
Si calcolano quindi le frequenze marginali della tabella per verificare che la regola aggiunga informazione: la confidenza è calcolata in relazione al supporto del conseguente.
Infatti, l’antecedente è gia verificato dall’algoritmo di formulazione, ma solamente regole con un conseguente frequente possono aggiungere informazione.
Si calcola quindi il <em>fattore di interesse</em>:</p>
<p><span class="math display">\[Lift = \frac{c(A \rightarrow B)}{s(B)}\]</span></p>
<p>oppure</p>
<p><span class="math display">\[I(A, B) = \frac{s(A, B)}{s(A) \cdot s(B)} = N \frac{f_{1.1}}{f_{1.\cdot} \cdot f_{\cdot.1}}\]</span></p>
<p>che assume il valore 1 in caso di indipendenza tra i due item.
Si calola anche il <em>Coefficiente di Correlazione</em>:</p>
<p><span class="math display">\[Phi = \frac{f_{1.1} \cdot f_{0.0} - f_{0.1} \cdot f_{1.0}}{\sqrt{f_{1.\cdot} \cdot f_{\cdot.1} \cdot f_{0.\cdot} \cdot f_{\cdot.0}}}\]</span></p>
<p>o l’<em>IS Measure</em>:</p>
<p><span class="math display">\[IS(A, B) = \sqrt{I(A, B) \cdot s(A, B)} = \frac{S(A, B)}{\sqrt{s(A) \cdot s(B)}}\]</span></p>
<p>che è una buona misura per verificare l’associazione di parole all’interno di testi; è semplificabile <span class="math inline">\(\sqrt{s(A) \cdot s(B)}\)</span> come in caso di indipendenza tra le due variabili.</p>
<p>Una misura si dice <em>simmetrica</em> se scambiando antecedente e conseguente il suo valore non cambia, <em>asimmetrica</em> altrimenti.
Esistono comunque una quarantina di misure diverse per calcolare il valore di una regola, e la letteratura suggerisce anche delle particolari misure per ogni dominio.
Alcuni attributi sono più adatti a misurare le prestazioni in caso di regole simmetriche o asimmetriche.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
