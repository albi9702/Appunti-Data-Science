<!DOCTYPE html>
<html lang="it" xml:lang="it">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Appunti - Decision Models</title>
  <meta name="description" content="Appunti - Decision Models" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Appunti - Decision Models" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Appunti - Decision Models" />
  
  
  

<meta name="author" content="Alberto Filosa" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a > Decision Models </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#decision-making"><i class="fa fa-check"></i><b>1</b> Decision Making</a></li>
<li class="chapter" data-level="2" data-path=""><a href="#linear-programming"><i class="fa fa-check"></i><b>2</b> Linear Programming</a><ul>
<li class="chapter" data-level="2.1" data-path=""><a href="#risoluzione-grafica"><i class="fa fa-check"></i><b>2.1</b> Risoluzione Grafica</a></li>
<li class="chapter" data-level="2.2" data-path=""><a href="#assunzioni"><i class="fa fa-check"></i><b>2.2</b> Assunzioni</a></li>
<li class="chapter" data-level="2.3" data-path=""><a href="#simplex-method"><i class="fa fa-check"></i><b>2.3</b> Simplex Method</a></li>
<li class="chapter" data-level="2.4" data-path=""><a href="#sensitivity-analysis"><i class="fa fa-check"></i><b>2.4</b> Sensitivity Analysis</a></li>
<li class="chapter" data-level="2.5" data-path=""><a href="#integer-linear-programming"><i class="fa fa-check"></i><b>2.5</b> Integer Linear Programming</a></li>
<li class="chapter" data-level="2.6" data-path=""><a href="#network-model"><i class="fa fa-check"></i><b>2.6</b> Network Model</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path=""><a href="#non-linear-programming"><i class="fa fa-check"></i><b>3</b> Non Linear Programming</a><ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#bisection-method"><i class="fa fa-check"></i><b>3.1</b> Bisection Method</a></li>
<li class="chapter" data-level="3.2" data-path=""><a href="#newton-method"><i class="fa fa-check"></i><b>3.2</b> Newton Method</a></li>
<li class="chapter" data-level="3.3" data-path=""><a href="#gradient-method"><i class="fa fa-check"></i><b>3.3</b> Gradient Method</a></li>
<li class="chapter" data-level="3.4" data-path=""><a href="#newton-method-1"><i class="fa fa-check"></i><b>3.4</b> Newton Method</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path=""><a href="#metaheuristics"><i class="fa fa-check"></i><b>4</b> Metaheuristics</a><ul>
<li class="chapter" data-level="4.1" data-path=""><a href="#hill-climbing"><i class="fa fa-check"></i><b>4.1</b> Hill Climbing</a></li>
<li class="chapter" data-level="4.2" data-path=""><a href="#simulated-annealing"><i class="fa fa-check"></i><b>4.2</b> Simulated Annealing</a></li>
<li class="chapter" data-level="4.3" data-path=""><a href="#tabu-search"><i class="fa fa-check"></i><b>4.3</b> Tabu Search</a></li>
<li class="chapter" data-level="4.4" data-path=""><a href="#genetic-algorithm"><i class="fa fa-check"></i><b>4.4</b> Genetic Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path=""><a href="#decision-trees"><i class="fa fa-check"></i><b>5</b> Decision Trees</a><ul>
<li class="chapter" data-level="5.1" data-path=""><a href="#risk-aversion"><i class="fa fa-check"></i><b>5.1</b> Risk Aversion</a></li>
<li class="chapter" data-level="5.2" data-path=""><a href="#value-of-information"><i class="fa fa-check"></i><b>5.2</b> Value of Information</a></li>
</ul></li>
<li class="divider"></li>
<li><a href = "https://github.com/rstudio/bookdown" target = "blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Appunti - Decision Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Appunti - Decision Models</h1>
<p class="author"><em>Alberto Filosa</em></p>
<p class="date"><em>30/6/2020</em></p>
</div>
<div style="page-break-after: always;"></div>
<div id="decision-making" class="section level1">
<h1><span class="header-section-number">1</span> Decision Making</h1>
<p>Un importante e difficile compito in una azienda di business è quella di prendere una decisione incerta, soprattutto dettata dalla presenza di svariati fattori da prendere in considerazione.
Per <strong><em>decision making</em></strong> si intende un processo di scelta logica tra diverse opzioni e affidarsi successivamente a future azioni.
Quando si prende una decisione è necessario considerare tutte le alternative e pesare gli aspetti positivi e negativi della scelta appena compiuta.</p>
<p>I problemi possono essere <em>strutturati</em> e <em>programmati</em>, di conseguenza gli obiettivi sono chiari, ricorrenti e facilmente definiti, oltre che ripetitivi.
Viceversa, essi possono essere non strutturati e non programmati, di conseguenza unici con le informazioni ambigue ed incomplete.
Nelle decisioni incerte si prevede la probabilità di un eventuale risultato con il corrispondente fattore di rischio.</p>
<p>Per prendere una decisione si deve utilizzare un <strong><em>decision model</em></strong> che predice l’output di una decisione per capire o controllare un problema.
Il modello deve anche predire cosa succede se viene presa una certa azione, in modo da massimizzare i fattori desiderabili e minimizzare quelli non desiderabili.
Il computer esamina le informazioni utilizzando metodi matematici per trovare dei pattern nei dati.
Le <em>analytics</em> studiano dati storici per cercare possibili trend nei dati e predire i dati del futuro. Essa prende in considerazione tre step:</p>
<ol style="list-style-type: decimal">
<li><em>Analisi Descrittiva</em> (anche chiamata esplorativa), che estrae informazioni dai dati calcolando indici descrittivi quali moda, media, mediana, varianza, deviazione standard. Inoltre, è possibile esplorare i dati tramite rappresentazioni grafiche quali istogrammi, boxplot e scatterplot;</li>
<li><em>Analisi Predittiva</em>, che costruisce modelli di previsione di <em>forecasting</em> quali serie storiche e autocorrelazione, e modelli di <em>data mining</em> come i modelli lineari, decision tree, ecc;</li>
<li><em>Analisi Prescrittiva</em>, che determina cosa deve verificarsi e come far accadere l’evento, ad esempio la <em>what-if analysis</em>. In questo modo è possibile portare i fattori a risultati desiderabili. Esempi sono il Linear Programming, la Sensitivity Analyisis e la Integer Linear Programming.</li>
</ol>
<p><img src="Immagini/decision-making.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="linear-programming" class="section level1">
<h1><span class="header-section-number">2</span> Linear Programming</h1>
<p>I modelli sono uno strumento essenziale per risolvere problemi decisionali, in quanto non tutti possono essere modellati tramite semplici modalità.
Quando si compie una decisione si deve scegliere una modalità tra le alternative, principalmente secondo la logica della vincita-perdita: questo fenomeno è chiamato <em>Frame Effect</em>.
I modelli decisionali aiutano le aziende nel compiere ottime decisioni, ma non garantiscono che il risultato sia sempre positivo; comunque è sempre meglio rispetto a prendere decisioni azzardate.</p>
<p>I modelli devono essere molto accurati in modo da ottenere risultati consistenti, per cui avviene un processo di <em>ottimizzazione</em> per ottenere il miglior risultato utilizzando una parte limitata di risorse.
L’ottimizzazione presenta le seguenti caratteristiche:</p>
<ul>
<li>Bisogna definire una <em>funzione obiettivo</em>, che deve essere minimizzata o massimizzata (in base al tipo di studio);</li>
<li>Si utilizzano un numero limitato di <em>variabili di decisione</em> che controllano il valore della funzione obiettivo;</li>
<li>Si definiscono i <em>vincoli</em> che specificano il range di accettabilità dei valori delle variabili coniderate nel modello.</li>
</ul>
<p>In definitiva, il problema di ottimizzazione consiste nel trovare il valore delle variabili di decisione del modello che minimizza o massimizza la funzione obiettivo, <span class="math inline">\(f_0(X_1, X_2, \dots, X_n,)\)</span>, e che soddisfa anche i vincoli imposti. Un problema di ottimizzazione lineare si scrive nel seguente modo:</p>
<p><span class="math display">\[\begin{matrix}
  \text{max (o min)} &amp; f_0(X_1, X_2, \dots, X_n)          \\
  \text{rispetto a } &amp; f_1(X_1, X_2, \dots, X_n) &amp; \le &amp; b_1 \\
                     &amp;          \vdots           &amp;     &amp;     \\
                     &amp; f_k(X_1, X_2, \dots, X_n) &amp;  =  &amp; b_k \\
                     &amp;          \vdots           &amp;     &amp;     \\
                     &amp; f_m(X_1, X_2, \dots, X_n) &amp; \ge &amp; b_m \\
  \end{matrix}\]</span></p>
<p>Se tutte le funzioni in un processo di ottimizzazione sono lineari (sia funzioni obiettivo che vincoli imposti), si avrà un problema di ottimizzazione lineare.
In generale, le fasi di ottimizzazione di un problema LP si formulano in 5 passaggi:</p>
<ol style="list-style-type: decimal">
<li>Comprendere il problema;</li>
<li>Identificare il numero e le varibili da considerare ed inserire nel modello;</li>
<li>Stabilire la funzione obiettivo come combinazione lineare delle variabili;</li>
<li>Stabilire i vincoli come combinazione lineare delle variabili;</li>
<li>Identificare ogni limite superiore o inferiore delle variabili di decisione.</li>
</ol>
<div id="risoluzione-grafica" class="section level2">
<h2><span class="header-section-number">2.1</span> Risoluzione Grafica</h2>
<p>Oltre alla risoluzione matematica, è possibile risolvere i problemi LP tramite un approccio grafico: i vincoli definiscono una regione di accettazione, dato che essi definiscono delle rette, ed il miglior punto nello spazio è la soluzione ottimale del problema.</p>
<p>Nel caso di un problema lineare con due variabili, i passaggi da seguire sono i seguenti:</p>
<ol style="list-style-type: decimal">
<li>Rappresentare graficamente i confini dei vincoli imposti dal modello;</li>
<li>Identificare la regione di accettazione;</li>
<li>Localizzare la soluzione ottimale tramite le curve di leva o identificando i punti estremi.</li>
</ol>
<p><img src="Immagini/LP-Graphic.PNG" width="100%" style="display: block; margin: auto;" /></p>
<p>In un problema lineare si possono presentare anche delle anomalie: si possono ottenere soluzioni <em>alternative</em>, ovvero più valori ottimali; vincoli <em>ridondanti</em>, che non contribuiscono a delineare la regione di accettazione (si potrebbero rimuovere, ma potrebbero modificare i valori della funzione obiettivo); soluzione <em>illimitata</em>, nella quale la regione di accettazione non presenta limiti; regione <em>infattibile</em>, nella quale due vincoli non si intersecano e non generano alcuna regione di accettazione.</p>
</div>
<div id="assunzioni" class="section level2">
<h2><span class="header-section-number">2.2</span> Assunzioni</h2>
<p>Dato che la funzione obiettivo del modello lineare è anch’esso lineare, il modello ed i vincoli saranno <em>proporzionali</em>, ovvero il contributo della funzione obiettivo da ogni variabile è proporzionale al valore della variabile di decisione, e <em>additivi</em>, ovvero il contributo della funzione obiettivo è indipendente dai valori di altre variabili di decisione.
Ovviamente queste assuzioni vanno ad influire anche sui vincoli imposti dal modello. Inoltre, il modello è <em>divisibile</em>, ovvero ogni variabile di decisione permette valori in frazione, e <em>certo</em>, ovvero ogni parametro è noto.</p>
</div>
<div id="simplex-method" class="section level2">
<h2><span class="header-section-number">2.3</span> Simplex Method</h2>
<p>Il <strong><em>simplex method</em></strong> è un algoritmo utilizzato per individuare la soluzione ottimale per il problema lineare.
Inanzitutto, è necessario convertire tutte le disequazioni del linear programming in equazioni aggiungendo delle variabili chiamate <em>slack</em>. In base al tipo di disequazione (<span class="math inline">\(+s_k\)</span> se c.l <span class="math inline">\(\leq\)</span>, altrimenti <span class="math inline">\(-s_k\)</span>) si somma/sottrae la suddetta variabile alla combinazione lineare:</p>
<p><span class="math display">\[\begin{aligned}
    a_{k1}X_1 + \dots + a_{kn}X_n + S_k = b_k \\
    a_{k1}X_1 + \dots + a_{kn}X_n - S_k = b_k
  \end{aligned}\]</span></p>
<p>In un sistema con <span class="math inline">\(n\)</span> variabili in <span class="math inline">\(m\)</span> equazioni (con <span class="math inline">\(n \geq m\)</span>) si selezionano tutte le <span class="math inline">\(m\)</span> variabili per risolvere il sistema di equazioni, mentre le restanti <span class="math inline">\(n-m\)</span> variabili vengono fissate a 0.</p>
<p>L’algoritmo identifica ogni punto estremo del problema, chiamato <em>basic feasibile solution</em>, e successivamente si muove ad un altro punto estremo adiacente in modo da migliorare il valore della funzione obiettivo.
Questo processo avviene scambiando una <em>basic variable</em> con una non basica al fine di crearne delle nuove.
Nel momento in cui alcun punto estremo adiacente ha un valore della funzione obiettivo maggiore, il processo si stoppa e l’ultimo valore individuato sarà quello ottimale.</p>
</div>
<div id="sensitivity-analysis" class="section level2">
<h2><span class="header-section-number">2.4</span> Sensitivity Analysis</h2>
<p>Quando si risolve un problema di ottimizzazione lineare si pensa di assumere che i valori dei coefficienti predetti dal modello siano certi, in realtà raramente ciò avviene.
La <em>sensitivity analysis</em> aiuta nel capire quanto è sensibile il cambiamento dei coefficienti del modello individuando la soluzione ottimale.
Gli approcci possono essere principalmente due:</p>
<ul>
<li>Cambiare i dati e rifar partire il modello (alcune volte è l’unico approccio utilizzabile);</li>
<li>Utilizzare il <em>simplex method</em> che implementa al suo interno report sulla sensibilità del modello costruito.</li>
</ul>
<p>In questo modo è possibile rispondere a domande quali quanto è possibile modificare la funzione obiettivo senza il cambiamento della soluzione ottimale, l’impatto del valore della funzione obiettivo sui cambiamenti dei vincoli e delle variabili di decisione.</p>
<p>Se le variabili slack (<span class="math inline">\(S\)</span>) dei vincoli sono nulli allora i vincoli sono <em>binding</em> in modo da prevenire valori troppo elevati della funzione obiettivo.
Il valore della variabile <em>slack</em> indica la differenza tra gli estremi dei vincoli, <span class="math inline">\(LHS - RHS\)</span>.
Questi range vengono definiti ottimali poichè il valore della soluzione ottimale non si modifica cambiando i parametri della funzione obiettivo, assumendo che tutti i coefficienti rimangano costanti.</p>
<p>Ad esempio, si considera un parametro di una funzione obiettivo (<span class="math inline">\(C1\)</span>) con valore 350; esso può variare tra <span class="math inline">\(300 \leq C1 \leq 450\)</span> senza che si modifichi la soluzione ottimale, assumendo che i rimanenti coefficienti rimangano costanti.</p>
<p>Il prezzo contabile, in inglese <em>shadow price</em>, indica l’ammontare del cambiamento del valore della funzione obiettivo all’aumentare di una unità della Right Hand Side del vincolo, assumendo che tutti i coefficienti rimangano costanti.
Cambiando il valore della RHS per un vincolo <em>binding</em>, la regione di accettazione e la soluzione ottimale si modificano.</p>
<p>I costi ridotti indicano la differenza dei profitti marginali ed il valore per unità delle risorse consumate.
In base al tipo di problema di ottimizzazione ed al valore ottimale della variabile di decsione, il valore ottimane dei costi ridotti sarà maggiore, minore o uguale a zero:</p>
</div>
<div id="integer-linear-programming" class="section level2">
<h2><span class="header-section-number">2.5</span> Integer Linear Programming</h2>
<p>Se una o più variabili in un problema lineare devono assumere valori interi, si incorre in un <em>integer linear programming</em>, ovvero un problema lineare con un ulteriore vincolo, chiamato vincolo di integrità.
Variabili intere permetto di costruire modelli più accurati, dato che alcune variabili si riferiscono ad oggetti fisici, ma la risoluzione del problema diventa più complicata.</p>
<p>In un problema lineare, alcune volte si ottengono valori interi per la costruzione della regione di accettazione.
Una prima soluzione, non consigliata, è quella di arrotondare all’intero più vicino il valore; non sempre, però, è affidabile in quanto la soluzione arrotondata può essere non accettabile, per i vincoli imposti dal modello, o subottimale.
Una seconda soluzione è utilizzare l’algoritmo <em>Branch &amp; Bound</em>, che teoricamente può risolvere il problema ILP, ma praticamente richiede un alto sforzo computazionale.
L’algoritmo computa la soluzione di una serie di problemi lineari, chiamati anche <em>candidate problem</em>.</p>
<p>Siccome l’algoritmo B&amp;B necessita di un enorme sforzo in termini computazionali e quindi di tempo, esistono altri metodi che specificano un fattore di tolleranza subottimale, in inglese <em>stopping rule</em>, in modo da fermare l’algoritmo quando una soluzione intera è stata trovata in una percentuale della soluzione ottimale in termini globali.
In particolare, è possibile calcolare la soluzione ottimale per un problema LP, che definisce dei limiti per la il valore della funzione obiettivo, e utilizzarla per risolvere il problema ILP.
Per problemi di massimizzazione, la funzione obiettivo ottimale del problema LP è un limite superiore del valore ottimale intero, mentre per problemi di minimizzazione è un limite inferiore.</p>
<p>L’algoritmo Branch &amp; Bound segue questi step:</p>
<ol style="list-style-type: decimal">
<li>Fase di <em>inizializzazione</em>, nella quale si rivolve il problema LP senza la condizione di integralità. Se i risultati sono lineari, la si utilizza come soluzione ottimale intera. Altrimenti, se si vuole risolvere un problema di massimizzazione si assegna al valore della funzione obiettivo della miglior soluzione intera <span class="math inline">\(Z_{best} = -\infty\)</span>, altrimenti <span class="math inline">\(Z_{best} = +\infty\)</span>;</li>
<li>Fase di <em>Branching</em>: si definisce <span class="math inline">\(X_j\)</span> la variabile che viola la condizione di integralità, <span class="math inline">\(b_j\)</span> il suo valore non intero. Si approssima il valore della funzione obiettivo al più vicino intero <span class="math inline">\(\text{int}(b_j) \leq b_j\)</span>. In questo modo si risolvono due problemi lineari, la prima aggiungendo come vincolo <span class="math inline">\(X_j \leq \text{int}(b_j)\)</span>, mentre per il secondo <span class="math inline">\(X_j \geq \text{int}(b_j) + 1\)</span>, aggiungendoli in una lista di problemi candidati da risolvere;</li>
<li>Fase di <em>bounding</em>, risolvendo i sub-problemi definiti al punto precedente. Si presentano diversi modi:
<ol style="list-style-type: lower-alpha">
<li>Se la lista dei candidati è vuota, l’algoritmo si stoppa; altrimenti, si risolve uno dei problemi candidati;</li>
<li>Se la soluzione non è accettabile, si ritorna al punto 3a; altrimenti, si assegna <span class="math inline">\(Z_{cp}\)</span> il valore della funzione obiettivo come problema candidato;</li>
<li>Se <span class="math inline">\(Z_{cp} \nleq Z_{best}\)</span> per un problema di massimizzazione, o <span class="math inline">\(Z_{cp} \ngeq Z_{best}\)</span> per un problema di minimizzazione, si ritorna al punto 3a;</li>
<li>Se la soluzione attuale non rispetta la condizione di integralità e <span class="math inline">\(Z_{cp} \leq / \geq Z_{best}\)</span>, si ritorna al punto 2;</li>
<li>Se la soluzione soddisfa la condizione di integralità, è stata trovata una soluzione intera migliore e si assegna <span class="math inline">\(Z_{best} = Z_{cp}\)</span>; si ritorna al punto 3;</li>
</ol></li>
<li>Fase di stop, nella quale è stata trovata la soluzione ottimale.</li>
</ol>
</div>
<div id="network-model" class="section level2">
<h2><span class="header-section-number">2.6</span> Network Model</h2>
<p>Numerosi problemi di business possono essere rappresentati graficamente tramie la costruzione di <em>Network Flow</em>, definiti come una collezione di nodi connessi tramite archi.
Esistono 3 tipi di nodi:</p>
<ul>
<li>Offerta (classificato come numeri negativi);</li>
<li>Domanda (classificato come numeri positivi);</li>
<li>Trasbordo.</li>
</ul>
<p>Un primo modello è chiamato <em>Transhipment Problem</em>, legata al trasporto di prodotti in più negozi.
Una volta definita la funzione obiettivo da minimizzare (o massimizzare), è necessario definire i vincoli per ogni nodo.
Per un Minimum Cost Network, in base al numero totale di domanda e al numero totale di offerta si utilizza la regola di bilancio chiamata Balance of Flow applicata ad ogni nodo.
Il numero di archi determina il numero i variabili.</p>
<p>Il <em>Shortest Path Problem</em> si concentra sul minizzare il percorso dato un numero di tappe da compiere.
È un caso specifico del Transhipment Problem dove è presente un nodo di offera con valore (-1), un nodo di domanda con valore (+1) e tutti gli altri nodi hanno un valore di domanda/offerta (0).
Esistono due tipi di funzioni obiettivo per risolvere il problema:</p>
<ul>
<li>Trovare il tragitto più veloce, minimizzando il tempo di viaggio;</li>
<li>Trovare il tragitto panoramico più lungo, massimizzando i punti scenici.</li>
</ul>
<p>Una volta definita la funzione obiettivo, si costruiscono i vincoli come visto precedentemente.</p>
<p>L’<em>Equipment Replacement Problem</em> determina il periodo di tempo nella quale è necessario cambiare l’attrezzatura.
In base al tipo di offerta, è possibile sottoscrivere contratti che minimizzano le spese; può essere modellato come un Shortest Path Problem.</p>
<p>Alcuni problemi di network flow non necessitano di avere nodi di trasporto, ma solo nodi di domanda ed offerta, perciò trasporti da punto a punto; questi vengono chiamati <em>Transportation &amp; Assignment Problems</em>.
Una volta definita la funzione obiettivo, che solitamente si vuole minimizzare, si definiscono i vincoli riferiti alla massima capienza alla domanda di un singolo luogo.</p>
<p>I <em>Generalized Network Flow Problems</em> sono dei problemi nella quale si verificano nell’aumento (o diminuzione) di prodotti lungo gli archi.
Questi modelli richiedono modifiche alla modellazione; si formulano come i Transhipment Problem.</p>
<p>Il <em>Maximal Flow Problem</em> ha l’obiettivo di determinare la massima quantità di flusso in un network.
Il problema si risolve come il Transhipment Problem.</p>
<p>Nel caso di un network con <span class="math inline">\(n\)</span> nodi, si utilizza il <em>Spanning Tree Problem</em>, con <span class="math inline">\(n-1\)</span> archi che connettono tutti i nodi e che non contenogono dei loop.
Il <em>Minimal Spanning Tree Algorith</em> risolve il problema di determinare la connessione di tutti gli archi al minimo costo.
L’algoritmo segue i passaggi:</p>
<ol style="list-style-type: decimal">
<li>Selezionare un nodo, chiamata subnetwork;</li>
<li>Aggiungere al subnetwork corrente l’arco meno costoso che connette i nodi. Se sono presenti archi con stesso costo, se ne scene uno in arbitrariamente;</li>
<li>Se tutti i nodi sono nel subnetwork, si ottiene la soluzione ottimale. Altrimenti si ritorna al passo 2.</li>
</ol>
</div>
</div>
<div id="non-linear-programming" class="section level1">
<h1><span class="header-section-number">3</span> Non Linear Programming</h1>
<p>Fino ad adesso si è considerato solamente un problema di ottimizzazione lineare, ma non sempre è possibile risolvere questi tipi di problemi. Esistono anche i <em>Non Linear Programming</em> che presentano una funzione obiettivo ed una o più vincoli non lineari. Il procedimento di risoluzione è analogo a quelli visti in precedenza, definendo perciò le decision variables ed i vincoli, ma si utilizzano differenti algoritmi ed il peso computazionale è maggiore per la difficoltà di risoluzione.</p>
<p><img src="Immagini/Non-Linear-Programming.PNG" width="100%" style="display: block; margin: auto;" /></p>
<p>Non sempre la soluzione ottimale è individuata all’estremo della regione di accettazione come accadeva nei problemi LP, ma anche al suo interno. Di conseguenza, si dovranno utilizzare differenti algoritmo per individuare la optimal solution.</p>
<p>L’algoritmo inizia in un punto appartenente alla regione di accettazione e si muove nella parte della regione nella quale si ha il più veloce miglioramento, fino a quando non si trova la soluzione ottimale migliore. Non sempre la soluzione è la migliore in termini globali, ma alcune volte può essere una soluzione ottimale locale. Non è consigliato partire dall’origine, ma da un valore approssimato della stessa grandezza del valore ottimale.</p>
<div id="bisection-method" class="section level2">
<h2><span class="header-section-number">3.1</span> Bisection Method</h2>
<p>Il <em>Bisection Method</em> è un algoritmo utilizzato per risolvere i problemi di ottimizzazione non lineare. Prima di introdurre i passaggi di risoluzione, si introducono dei concetti matematici.</p>
<blockquote>
<p>Una equazione <span class="math inline">\(f(x) = 0\)</span>, con <span class="math inline">\(f(x)\)</span> continua su <span class="math inline">\(\mathbb{R}\)</span>, ha almeno una soluzione tra due punti <span class="math inline">\(x_i\)</span> e <span class="math inline">\(x_u\)</span> se <span class="math inline">\(f(x_l) \times f(x_u) &lt; 0\)</span></p>
</blockquote>
<p>Unimodality:</p>
<blockquote>
<p>Una funzione unimodale consiste in esattamente un aumento crescente e decrescente di una parte di funzione</p>
</blockquote>
<blockquote>
<p>Se la funzione <span class="math inline">\(f(x)\)</span> cambia segno tra due punti <span class="math inline">\(x_l\)</span> e <span class="math inline">\(x_u\)</span>, esiste almeno una soluzione per <span class="math inline">\(f(x) = 0\)</span> tra di essi.</p>
</blockquote>
<p>L’algoritmo si formula nei seguenti passaggi:</p>
<ol style="list-style-type: decimal">
<li>Scegliere due punti <span class="math inline">\(x_l\)</span> e <span class="math inline">\(x_u\)</span> tale che <span class="math inline">\(f(x_l) \times f(x_u) &lt; 0\)</span> (ovvero che cambia segno tra i due punti);</li>
<li>Stimare la soluzione <span class="math inline">\(x_m\)</span> come il punto medio tra <span class="math inline">\(x_l\)</span> e <span class="math inline">\(x_u\)</span></li>
</ol>
<p><span class="math display">\[x_m = \frac{x_l + x_u}{2}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Ridurre la grandezza dell’intervallo:
<ol style="list-style-type: lower-alpha">
<li>Se <span class="math inline">\(f(x_l) \times f(x_u) &lt; 0\)</span>, la soluzione non è vera tra <span class="math inline">\(x_l\)</span> e <span class="math inline">\(x_m\)</span> e si assegna <span class="math inline">\(x_u = x_m\)</span>;</li>
<li>Se <span class="math inline">\(f(x_l) \times f(x_u) &gt; 0\)</span>, la soluzione non è vera tra <span class="math inline">\(x_m\)</span> e <span class="math inline">\(x_u\)</span> e si assegna <span class="math inline">\(x_l = x_m\)</span></li>
<li>Se <span class="math inline">\(f(x_l) \times f(x_u) = 0\)</span>, la soluzione è <span class="math inline">\(x_m\)</span>. (STOP);</li>
</ol></li>
<li>Stimare la nuova soluzione <span class="math inline">\(x_m\)</span> e trovare l’errore relativo approssimato in termini assoluti:</li>
</ol>
<p><span class="math display">\[\lvert{\varepsilon_a}\rvert = \left\lvert \frac{x_m^{new} - x_m^{old}}{x_m^{new}} \right\rvert \times 100\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Comparare <span class="math inline">\(\lvert{\varepsilon_a}\rvert\)</span> con l’errore iniziale <span class="math inline">\(\varepsilon_s\)</span>:
<ol style="list-style-type: lower-alpha">
<li>Se <span class="math inline">\(\lvert{\varepsilon_a}\rvert &gt; \varepsilon_s\)</span>, ritornare al punto 2 utilizzando nuovi punti;</li>
<li>Si è individuata la soluzione ottimale.</li>
</ol></li>
</ol>
<p>I vantaggi principali di questo algoritmo sono la convergenza sempre garantita e che all’aumentare delle ierazioni ci si avvicina sempre di più allo zero. Tuttavia, la convergenza è molto lenta, anche se il valore iniziale è molto vicino allo zero.</p>
</div>
<div id="newton-method" class="section level2">
<h2><span class="header-section-number">3.2</span> Newton Method</h2>
<p>Un altro metodo di risoluzione per i problemi non lineari è chiamato <em>Newton Method</em>, che genera una sequenza di punti convergenti alla soluzione ottimale.
Esistono due tipi di algoritmi:</p>
<ul>
<li><em>Dicotomo</em>, che individua la soluzione della equazione della derivata pari a 0 ed ad ogni iterazione si riduce l’intervallo;</li>
<li>Bisection Method (visto in precedenza).</li>
</ul>
<p>I criteri di termine servono per terminare l’algoritmo, che si conclude se la soluzione è accurata ad un certo livello di tolleranza, se la soluzione ha un piccolo miglioramento, se si raggiunge il numero massimo di iterazione, se la soluzione diverge, se la soluzione è in un loop.</p>
<p>Il Newton Method adatta una soluzione quadratica a <span class="math inline">\(f(x)\)</span> utilizzando sia il gradiente che l’informazione di curvatura su <span class="math inline">\(x\)</span>.
I passaggi sono i seguenti:</p>
<ol style="list-style-type: decimal">
<li>Utilizzare l’approssimazione di Taylor:</li>
</ol>
<p><span class="math display">\[f(x+h) = f(x) + f&#39;(x) \times h + 1/2 f&#39;&#39;(x)h^2\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Trovare la soluzione di <span class="math inline">\(f&#39;\)</span>:</li>
</ol>
<p><span class="math display">\[f&#39;(x+h) = f&#39;(x) + f&#39;&#39;(x)h \implies h= - \frac{f&#39;(x)}{f&#39;&#39;(x)}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Si assume che <span class="math inline">\(x_{k+1} = x_k + h_k = x_k - \frac{f&#39;(x)}{f&#39;&#39;(x)}\)</span></li>
</ol>
<p>I vantaggi principali di questo algoritmo è che non necessita di trovare la soluzione perfetta e si ha una convergenza quadratica, ovvero l’accuratezza ottimale raddoppia ad ogni iterazione.
Tuttavia, la convergenza globale non è ottima e molte volte fallisce se il valore è troppo lontano dal minimo.</p>
</div>
<div id="gradient-method" class="section level2">
<h2><span class="header-section-number">3.3</span> Gradient Method</h2>
<p>Il <em>Gradient Method</em> è un algoritmo di ottimizzazione non lineare per problemi multivariati.
Per tutti metodi di ottimizzazione si sceglie la direzione <span class="math inline">\(d_k\)</span> da seguire partendo da un punto <span class="math inline">\(x_k\)</span>; successivamente, si massimizza (o minimizza) lungo la direzione il valore al fine di trovare un nuovo punto <span class="math inline">\(x_{k+1} = x_k + \alpha_k d_k\)</span>, con <span class="math inline">\(k\)</span> il numero di iterazione e <span class="math inline">\(\alpha_k\)</span> chiamata <em>Step Size</em>.
Esso viene calcolato minimizzando la seguente funzione (con <span class="math inline">\(x_k\)</span> e <span class="math inline">\(\nabla f(x_k)\)</span> note): <span class="math inline">\(\max f(x_{k+1}) = f(x_k + \alpha_k \nabla f(x_k))\)</span> e la si risolve utilizzando la derivata parziale per <span class="math inline">\(\alpha_k\)</span>:</p>
<p><span class="math display">\[\frac{\partial{f(x_k + \alpha_k \nabla f(x_k))}}{\partial{\alpha_k}} = 0\]</span></p>
<p><strong>N.B.:</strong> dato che il gradiente è definito come il cambiamento della funzione in quel punto, il gradiente è utilizzato come direzione di ricerca in modo da ridurre il numero di iterazioni.</p>
<p>Il <em>Steepest Descent Method</em> segue questi step:</p>
<ol style="list-style-type: decimal">
<li>Scegliere un punto iniziale <span class="math inline">\(x_0\)</span>;</li>
<li>Calcolare <span class="math inline">\(\nabla f(x_k)\)</span> alla k-esima iterazione;</li>
<li>Calcolare il vettore di ricerca <span class="math inline">\(d_k = \pm \nabla f(x_k)\)</span>;</li>
<li>Calcolare il punto successivo <span class="math inline">\(x_{k+1} = x_k \pm \alpha_k d_k\)</span>;</li>
<li>Utilizzare un metodo di risoluzione univariata per ottenere <span class="math inline">\(\alpha_k\)</span>;</li>
<li>Determinare la convergenza utilizzando una tolleranza <span class="math inline">\(|f(x_{x+1}) - f(x_k)| &lt; \varepsilon_1\)</span>, oppure <span class="math inline">\(||\nabla f(x_{k+1})|| &lt; \varepsilon_2\)</span>.</li>
</ol>
</div>
<div id="newton-method-1" class="section level2">
<h2><span class="header-section-number">3.4</span> Newton Method</h2>
<p>Il <em>Newton Method</em> esiste anche per i NLP multivariati.
Essa approssima una funzione <span class="math inline">\(f(x)\)</span> con un funzione quadratica nella vicinanza del punto utilizzando la espansione di Taylor:</p>
<p><span class="math display">\[f(x_k + \Delta x) ≈ f(x_k) + \nabla f(x_k) \Delta x + \Delta x H(x_k) \Delta x\]</span></p>
<p>Si vuole risolvere la seguente equazione:</p>
<p><span class="math display">\[\frac{\partial{f(x_k + \Delta x)}}{\partial{\Delta x}} = 0 
\implies \Delta x = - H(x_k)^{-1} \nabla f(x_k)\]</span></p>
<p>L’algoritmo segue questi step:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(K = 0\)</span>;</li>
<li>Scegliere un punto d’inizio <span class="math inline">\(x_k\)</span>;</li>
<li>Calcolare <span class="math inline">\(\nabla f(x_k)\)</span> e <span class="math inline">\(H(x_k)\)</span>;</li>
<li>Calcolare il Newton Step <span class="math inline">\(x_{k+1} = x_k - H(x_k)^{-1} \nabla f(x_k)\)</span>;</li>
<li>Se <span class="math inline">\(H(x_k)\)</span> è definita positiva, si arriva alla convergenza; altrimenti, ritornare al punto 2 con <span class="math inline">\(K + 1\)</span>.</li>
</ol>
<p>A differenza del Gradient Method, il metodo di Newton utilizza sia il gradiente che la matrice Hessiana.
Inoltre, riduce il numero di iterazioni richieste, ma aumenta il peso computazionale; di conseguenza, non è consigliato per funzioni molto complesse.</p>
</div>
</div>
<div id="metaheuristics" class="section level1">
<h1><span class="header-section-number">4</span> Metaheuristics</h1>
<p>Le <em>Metaeuristiche</em> sono delle procedure utilizzate dagli algoritmi per approssimare il valore nella quale la funzione converge; è spesso utilizzato con algoritmi molto complessi.
Una volta che la funzione converge, non sempre è garantita la soluzione ottimale, che sia un punto di minimo o massimo globale; molte volte accade che sia un punto di ottimizzazione locale.
Per risolvere questo problema, esistono dei meccanismi che cercano di evitare di essere intrappolati nello spazio di ricerca.
È spesso utilizzato per risolvere problemi molto complessi perchè esplora lo spazio di ricerca in modo efficacie per identificare le soluzioni possibili.
Dato che non sempre è garantita la convergenza, le metaeuristiche sono utilizzate assieme ai metodi esatti.</p>
<p><img src="Immagini/Local-Maximum.PNG" width="100%" style="display: block; margin: auto;" /></p>
<p>Esistono due modi per evitare la convergenza locale: la prima è aumentare lo step size in modo tale da identificare non solo la prima cima del massimo locale, ma potenzialmente anche la successiva.
Non è un metodo consigliato in quanto l’algoritmo potrebbe non convergere.
In alternativa, è possibile far girare il metodo in un grande loop, ogni volta che inizia da un punto e che trova il valore ottimale; così facendo, è possibile identificare la soluzione ottimale e confrontarla con le altre.
Questo <em>Try Hard</em> non è efficiente in quanto alcuni algoritmi hanno delle assunzioni molto stringenti.
Le metaeuritiche sono utili in quanto hanno poche o nessuna assunzione; sono metodi generali, ma spesso utili come ultima soluzione in modo da trovare la soluzione ottimale approssimata.</p>
<p>Per trovare le possibili soluzione, è necessario seguire questi passaggi:</p>
<ul>
<li>Avere delle possibili soluzioni iniziali, chiamata in inglese <em>Initialization Procedure</em>;</li>
<li>Valutare la qualità della soluzione, chiamata in inglese <em>Assessment Procedure</em>;</li>
<li>Copiare una soluzione candidata e modificare leggermente la soluzione con procedure leggermente diverse, chiamata in inglese <em>Modification Procedure</em>.</li>
</ul>
<p>Il termine metaeuristica è utilizzato per descrivere un ramo della ottimizzazione stocastica, ovvero una generica classe di algoritmi e tecniche che utilizza procedure casuali per individuare la soluzione ottimale (o l’approssimazione) per problemi molto complessi.
Inoltre, sono utilizzati per risolvere problemi con poche informazioni, ad esempio non si conosce che tipo di soluzione si vuole ottenere, non si conosce la direzione per il valore ottimale e la soluzione forza bruta richiede troppo spazio computazionale.</p>
<div id="hill-climbing" class="section level2">
<h2><span class="header-section-number">4.1</span> Hill Climbing</h2>
<p>Una delle procedure euristiche più utilizzate è chiamata <em>Hill Climbing</em>, che consiste nella iterazione di un punto fino alla ricerca del punto ottimale locale.
Esso è strettamente legato al metodo Gradient Ascent, ma non richiede la conoscenza del gradiente o la direazione di ottimizzazione.
Iterativamente identifica la soluzione candidata e viene sostituita se ne trova una migliore. La procedura segue questi passaggi:</p>
<ol style="list-style-type: decimal">
<li>Assegnare ad <span class="math inline">\(S\)</span> la soluzione iniziale candidata;</li>
<li>Modificare leggermente la soluzione <span class="math inline">\(S\)</span> (diventa <span class="math inline">\(R\)</span>);</li>
<li>Se <span class="math inline">\(\text{Qualità}_R &gt; \text{Qualità}_S\)</span>, allora si assegna ad <span class="math inline">\(S\)</span> il valore della leggera modifica e si ritorna al punto 2.</li>
</ol>
<p>Se la soluzione è quella ottimale, o se si ha raggiunto il limite massimo computazionale, allora si stoppa l’algoritmo.</p>
<p>Esiste un algoritmo, chiamato <em>Steepest Ascent Hill-Climbing</em>, che campiona <span class="math inline">\(n\)</span> trasformazioni desiderate per individuare i candidati ottimali.
Il procedimento è molto simile al precedente, la differenza principale è che si sceglie il numero di trasformazioni desiderate per campionare il gradiente e si assegna a <span class="math inline">\(W\)</span> il valore migliore identificato.</p>
<p>Le soluzioni possibili possono essere un vettore, una lista di oggetti di arbitraria lunghezza, un albero, un grafo o una combinazione di esse.
Una semplice e comune rappresentazione per una soluzione possibile è un vettore di valori reali.</p>
<p>Uno dei problemi principali di questo metodo è che se il random noise aggiunto è molto piccolo, non sarà in grado di identificare il valore ottimale globale, ma solo locale.
Dall’altro lato, se il random noise aggiunto è troppo grande, l’algoritmo avrà molta difficoltà per convergere e passerà da un picco all’altro senza identificare il valore ottimale globale.</p>
<p>Un algoritmo è ottimizzato globalmente se riesce ad identificare il valore ottimo globale.
L’algoritmo più semplice è chiamato <em>Random Search</em>, estremo nella esplorazione (e quindi nella ottimizzazione globale) a differenza del Hill Climbing, estremo nell’utiizzo (e quindi nella ottimizzazione locale).</p>
<p>Esistono due tipologie principali di metaeuristiche:</p>
<ul>
<li><em>Trajectory Based</em>: da una soluzione iniziale <span class="math inline">\(s_0\)</span> si generano le soluzioni possibili. Se la soluzione scelta è migliore di quella iniziale a partire da un intorno, la si utilizza come soluzione migliore ed il ciclo si termina quando si è individuata la soluzione ottimale;</li>
<li><em>Population Based</em>: da un insieme di soluzioni <span class="math inline">\(P_0\)</span>, si generano altre popolazioni di candidati e se sono migliori di quella iniziale, le si utilizzano come soluzioni migliori.</li>
</ul>
<p><img src="Immagini/Metaeutistich-SP.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="simulated-annealing" class="section level2">
<h2><span class="header-section-number">4.2</span> Simulated Annealing</h2>
<p>Il <em>Simulated Annealing</em> è un metodo di ottimizzazione stocastico senza vincoli: da un punto iniziale, al posto di ridurre la funzione di costo ad ogni iterazione come i metodi di ottimizzazione locali, considera accettando o rifiutando iterativamente punti candidati.
Il metodo converge individuando la soluzione migliore.</p>
<p><img src="Immagini/Simulated-Annealing.PNG" width="100%" style="display: block; margin: auto;" /></p>
<p>Il vantaggio principale è che questo metodo controlla intelligentemente il grado di casualità aggiunta al metodo stocastico di ricerca in modo da aumentae la possibilità di individuare la soluzione ottima globale: inizialmente la casualità della funzione di valutazione è molto alta, mentre la temperatura diminuisce in base ad un <em>Annealing Schedule</em> predeterminato.</p>
<p>L’algoritmo segue questi passaggi:</p>
<ol style="list-style-type: decimal">
<li>Scegliere un punto iniziale <span class="math inline">\(X = X_0\)</span> (<span class="math inline">\(K = 0\)</span>);</li>
<li>Valutare la funzione di costo <span class="math inline">\(F = f(X_k)\)</span>;</li>
<li>Spostare casualmente <span class="math inline">\(X_k\)</span> ad una nuova soluzione <span class="math inline">\(X_{k+1}\)</span>;</li>
<li>Se <span class="math inline">\(f(X_{k+1}) &lt; F\)</span>, allora accettare la nuova soluzione. La nuova soluzione sarà <span class="math inline">\(X = X_{k+1}\)</span> e <span class="math inline">\(F = f(X_{k+1})\)</span>;</li>
<li>Se <span class="math inline">\(f(X_{k+1}) &gt; F\)</span>, allora accettare la nuova soluzione con una certa probabilità e la nuova soluzione sarà <span class="math inline">\(X = X_{k+1}\)</span> e <span class="math inline">\(F = f(X_{k+1})\)</span> se un numero casuale è minore di <span class="math inline">\(\varepsilon\)</span>, costante o casuale;</li>
<li>Si passa allo step successivo <span class="math inline">\(K = K+1\)</span> e si ritorna al punto 2.</li>
</ol>
<p>Il valore dell’errore è definito dal <em>Metropolis criterion probability of acceptance</em>, che sfrutta la distribuzione di Boltzmann per calcolare la probabilità:</p>
<p><span class="math display">\[\varepsilon = \exp \left [ -\frac{f(X_{k+1})- F}{T_{k+1}} \right ]\]</span></p>
<p>con <span class="math inline">\(T_{k+1}\)</span> un parametro che diminuisce gradualmente. Il valore avrà una alta temperatura se cerca di accettare tutte le soluzioni anche se il numeratore è grande, mentre avrà una bassa temperatura se accetta solamente la nuova soluzione dove il numeratore è piccolo.</p>
</div>
<div id="tabu-search" class="section level2">
<h2><span class="header-section-number">4.3</span> Tabu Search</h2>
<p>Il <em>Tabu Search</em> è un metodo metauristico che ha la particolarità di saltare alcune zone dello spazio di ricerca e che ricerca il valore ottimale utilizzando penalità e bonus.
In particolare, utilizza una struttura che esplora la storia di ricerca; è una via di mezzo tra il Branch &amp; Bound ed il Simulated Annealing.
Esso utilizza una memoria extra per evitare dei loop durante la procedura e per diversificare la ricerca del punto ottimale; inoltre, sfrutta la memoria per classificare un sottoinsieme di movimenti in un intorno come <strong>tabù</strong>, creandone una lista.</p>
<p>Questo metodo ha una importante eccezione, chiamata <em>Aspiration Criterion</em>: se nello spostamento esiste una soluzione migliore, la classificazione viene riscritta.</p>
<p>Il metodo segue questi passaggi:</p>
<ol style="list-style-type: decimal">
<li>Creare una soluzione iniziale;</li>
<li>Creare una lista di candidati dalle soluzioni precedenti;</li>
<li>Valutare la soluzione ed individuare la migliore soluzione accettabile;</li>
<li>Se la condizione di stop è soddisfatta, si è individuat la soluzione ottimale; altrimenti, si aggiornano le condizioni di Tabu e l’Aspiration Criterion.</li>
</ol>
<!--I passaggi da seguire sono raffigurati nella seguente immagine:

<img src="Immagini/Tabu-Search.png" width="100%" style="display: block; margin: auto;" />

-->
<p>Si presentano le condizioni di stop se l’algoritmo non converge:</p>
<ul>
<li>Se <span class="math inline">\(N(i, K+1) = 0\)</span>, ovvero se non è presente alcuna soluzione nell’intorno della soluzione <span class="math inline">\(i\)</span>;</li>
<li><span class="math inline">\(K\)</span> è più grande del numero massimo di iterazioni;</li>
<li>Il numero di interazioni dell’ultimo miglioramento <span class="math inline">\(i^*\)</span> è più grande di un numero specifico;</li>
<li>L’evidenza porta ad un risultato migliore rispetto alla soluzione ottimale.</li>
</ul>
</div>
<div id="genetic-algorithm" class="section level2">
<h2><span class="header-section-number">4.4</span> Genetic Algorithm</h2>
<p>Basato sulla idea della evoluzione bioligica Darwiniana, il <em>Genetic Algorithm</em> è un metodo utilizzato per risolvere vari problemi difficili.</p>
<p>L’algoritmo segue questi passaggi:</p>
<ol style="list-style-type: decimal">
<li>Generare un insieme di soluzioni randomiche da una popolazione di cromosomi;</li>
<li>Per ogni generazione, ripetere fino a quando non è stata individuata la soluzione ottimale:
<ol style="list-style-type: lower-alpha">
<li>Calcolare ogni soluzione dei cromosomi;</li>
<li>Selezionare casualmente una coppia di cromosomi parenti;</li>
<li>Generare i cromosomi figli utilizzando la procedura <em>Crossover</em>, selezionando due cromosomi parenti e combinando i loro geni per produrre i cromosomi figli, e <em>Mutation</em>, nella quale ogni cromosoma figlio può modificarsi randomicamente.</li>
</ol></li>
</ol>
<p>Questo algoritmo alcune volte cifra le soluzioni come una stringa di bit; ognuno di esso rappresenta un aspetto per la soluzione al problema ed è necessario testare ogni stringa per ottenere un punteggio sulla bontà della soluzione.</p>
<p>In questo metodo lo spazio di ricerca può essere visto come una superficie, in questo caso l’altezza ed ogni possibile soluzione è definito come punto nello spazio.
Per una semplice funzione il <em>Search Space</em> è uni-dimensionale, ma codificando molti valori dei cromosomi è possibile ricercare il punto ottimale in più dimensioni.
L’algoritmo cerca di muoversi nei punti con un alto fitness nello spazio.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="decision-trees" class="section level1">
<h1><span class="header-section-number">5</span> Decision Trees</h1>
<p>Prima di definire cosa sono i Decision Tree, è necessario introdurre il concetto di <em>Decision Making</em>, definito come la possibilità di prendere una buona decisione in base ad una serie di analisi compiute.
Esistono due tipologie di prolemi:</p>
<ul>
<li>Problemi strutturati, nella quale gli obiettivi sono chiari, dato che precedentemente accaduti e le informazioni a riguardo sono noti e completi;</li>
<li>Problemi non strutturati, nuovi o inusuali nella quale l’informazione è ambigua, incompleta che generi una unica risposta.</li>
</ul>
<p>Le condizioni per prendere una decisione possono essere <em>certe</em>, nella quale tutte le possibili risposte sono note ed è possibile prendere accurate decisioni.
Tuttavia, molte volte le condizioni sono <em>incerte</em> in quanto non si conoscono tutte le possibili risposte.
Se una possibile soluzione è nota, allora è possibile stimare la verosimiglianaza della risposta certa, chiamata rischio.</p>
<p>La Decision Analysis è necessaria per prendere delle accurate decisioni ed è caratterizzata da diverse azioni;</p>
<p><strong>Orderability</strong>: <span class="math inline">\(\quad\)</span> per ogni coppia di risposte iniziali, si preferisce la decisione <span class="math inline">\(A\)</span> a <span class="math inline">\(B\)</span>, <span class="math inline">\(B\)</span> ad <span class="math inline">\(A\)</span> oppure <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> sono entrambe preferibili.</p>
<p><strong>Transitivity</strong>: <span class="math inline">\(\quad\)</span> se la decisione <span class="math inline">\(A\)</span> è meglio di <span class="math inline">\(B\)</span> e <span class="math inline">\(B\)</span> meglio di <span class="math inline">\(C\)</span>, allora <span class="math inline">\(A\)</span> è meglio di <span class="math inline">\(C\)</span>.</p>
<p><strong>Continuity</strong>: <span class="math inline">\(\quad\)</span> se si preferisce la decisione <span class="math inline">\(A\)</span> a <span class="math inline">\(B\)</span> e <span class="math inline">\(B\)</span> a <span class="math inline">\(C\)</span>, allora esiste una certa probabilità nella quale si preferisce utilizzare questa lotteria.</p>
<p><strong>Substitutability</strong>: <span class="math inline">\(\quad\)</span> se si preferisce la decisione <span class="math inline">\(A\)</span> a <span class="math inline">\(B\)</span>, allora date due identiche lotterie, in una presente <span class="math inline">\(A\)</span> e nell’altra <span class="math inline">\(B\)</span>, si preferisce quella che contiene <span class="math inline">\(A\)</span>.</p>
<p><strong>Monotonicity</strong>: <span class="math inline">\(\quad\)</span> se si preferisce la decisione <span class="math inline">\(A\)</span> a <span class="math inline">\(B\)</span>, e se la probalità di <span class="math inline">\(A\)</span> pari a <span class="math inline">\(p\)</span> è più grande di quella di <span class="math inline">\(B\)</span> pari a <span class="math inline">\(q\)</span>, allora si preferisce una lotteria che preferisce <span class="math inline">\(A\)</span> su <span class="math inline">\(B\)</span> con alta probabilità.</p>
<p><strong>Decomposability</strong>: <span class="math inline">\(\quad\)</span> data una lotteria a due stadi, nella prima <span class="math inline">\(A\)</span> con probabilità <span class="math inline">\(p\)</span> e nella seconda <span class="math inline">\(B\)</span> con probabilità <span class="math inline">\(q\)</span> e <span class="math inline">\(C\)</span> con probabilità <span class="math inline">\(1-q\)</span>, è equivalente costruire una lotteria a singolo stadio con tre possibile risposte: <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> con stessa probabilità di prima e <span class="math inline">\(C\)</span> con probabilità <span class="math inline">\((1-p)(1-q)\)</span>.</p>
<p>Se vengono soddisfatte queste assunzioni, allora esiste una funzione <span class="math inline">\(U\)</span> tale che se si preferisce <span class="math inline">\(A\)</span> a <span class="math inline">\(B\)</span>, allora <span class="math inline">\(U(A) &gt; U(B)\)</span> mentre se sono entrambe preferibili, allora <span class="math inline">\(U(A) = U(B)\)</span>.</p>
<p>L’utilità della lotteria è definita come il valore atteso della utility della risposta:</p>
<p><span class="math display">\[U(L) = p U(A) + (1-p)U(B)\]</span></p>
<p>Il <em>Decision Tree</em> è definito come il modello analitico utilizzato nella Decision Analysis.
Più è complessa l’analisi, più sarà complessa la decisione da prendere.
La risposta non è certa, in quanto esistono numerosi fattori da prendere in considerazione; è necessario raccogliere informazioni per ridurre l’incertezza, ma comunque l’attitudine al rischio impatta le decisioni prese.</p>
<p>Esistono tre tipi di nodi:</p>
<ul>
<li><em>Decision Node</em>, che presenta le possibili alternative;</li>
<li><em>Chanche Node</em>, che presenta le possibili riposte di sviluppo;</li>
<li><em>End Point</em>, che rappresenta la fine del problema.</li>
</ul>
<p><img src="Immagini/Decision-Tree.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Il valore atteso è una ottima misura utilizzata nel lungo periodo ed è definita come il valore medio che ci si aspetta selezionando una alternativa:</p>
<p><span class="math display">\[EV = \sum_{i=1}^k P(X_i)X_i\]</span></p>
<div id="risk-aversion" class="section level2">
<h2><span class="header-section-number">5.1</span> Risk Aversion</h2>
<p>Il valore di una alternativa rischiosa può essere differente rispetto al valore atteso.
La certezza equivalente, in inglese <em>Certainty Equivalent</em>, per una alternativa è definita come una quantità certa preferibile all’alternativa.</p>
<p>L’attitudine al rischio può essere di tre tipologie:</p>
<ul>
<li>Risk Averse: <span class="math inline">\(CE &lt; EV\)</span></li>
<li>Risk Neutral: <span class="math inline">\(CE = EV\)</span></li>
<li>Risk Seeking: <span class="math inline">\(CE &gt; EV\)</span></li>
</ul>
<p>Una Utility Function traduce il risultato in numeri tali per cui il valore atteso dei numeri di utility possono essere utilizzati per calcolare la Certainty Equivalent per le alternative in termini consistenti con una attitudine del decision maker tendente al rischio.</p>
<p>La <em>Exponential Utility Function</em> è una famosa funzione utilizzata per calcolare il rischio di tolleranza; la funzione è definita come <span class="math inline">\(u(x) = 1 - e^{-x/R}\)</span>, con <span class="math inline">\(R &gt; 0\)</span> e nota.
Se il rischio di tolleranza <span class="math inline">\(R\)</span> aumenta la Utility Function sarà meno avversa al rischio.
Per ogni utility function esiste una specifica certanty equivalente; in questo caso, <span class="math inline">\(CE = -R ln(1-E[U])\)</span>.</p>
<p>La differenza tra Expected Value ed il Certainty Equivalent può essere definito come il livello di rischio nel prendere una decisione rispetto ad un altra.</p>
</div>
<div id="value-of-information" class="section level2">
<h2><span class="header-section-number">5.2</span> Value of Information</h2>
<p>L’informazione perfetta rimuove tutta l’incertezza riguardo il risultato delle alternative ed è definita come il limite superiore del valore della informazione.
Un parametro importante è chiamato valore atteso della informazione, definito come il massimo profitto atteso con informazione sommato al costo della consulenza sottratto al massimo profitto atteso senza informazione.
Di conseguenza, è utile avere più informazione possibile in modo da migliorare il valore previsto di profitto.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
